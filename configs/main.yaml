# @package _global_
defaults:
  - _self_  # merges main.yaml itself
  - /data    # merges data.yaml
  - /model   # merges model.yaml
  - optional user: env # optional environment settings to add
  - override /hydra/hydra_logging@_group_: none # Disable Hydra logging
  - override /hydra/job_logging@_group_: none # Disable Hydra logging


# ! Path
project_root: ${hydra:runtime.cwd}
dirs:
  data_storage: ${project_root}/datasets/   # For datasets
  hydra: ${.temp}hydra/
  output: ${project_root}/generated_files/output/${model.name}/${uid}/ # For files to be saved, to be initialized
  # output: ${project_root}/generated_files/output/${model.name}/ # For files to be saved, to be initialized

  fingerprint_storage: ${project_root}/generated_files/fingerprint/  # For fingerprint files


  checkpoint_dir: ${project_root}/generated_files/checkpoints/${model.name}/${uid}/  # For model checkpoints
  # checkpoint_dir: ${project_root}/generated_files/checkpoints/${model.name}/

  temp: ${project_root}/generated_files/temp/working_dir/${uid}/
  # temp: ${project_root}/generated_files/temp/working_dir/


res_file: ${dirs.output}seed${seed}_results.json
uid: null # To be generated in the main program
seed: 0
remove_dir: false

pretrain:
  seed: 42
  gpu: 1
  pretrain_datasets: ['pubmed', 'arxiv', 'wikics', 'amazon-ratings']
  train_tasks: ['pubmed_link','pubmed_node','arxiv','wikics', 'amazon-ratings']
  eval_tasks: ['cora_node']
  use_original_mask: false
  pretrain_epochs: 8000

  k_shot: 5
  m_way: 10
  t_query: 1
  n_eqisodes: 100

  min_delta: 0.001
  patience: 10000
  log_every_n_steps: 1
  check_val_every_n_epoch: 5
  
wandb:
  project: "GAlign-Pretrain-Ali"
  debug: false

logging:
  level: info
  enable_stdout_log: true
  log_wandb_metric_to_stdout: False
  prefix: ''


# @ Hydra
hydra:
  run:
    dir: ${dirs.hydra}