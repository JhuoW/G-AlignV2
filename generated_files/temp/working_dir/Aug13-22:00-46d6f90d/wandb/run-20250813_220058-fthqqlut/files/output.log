Epoch 0: Loss = 1.039200
Epoch 20: Loss = 1.056895
Epoch 40: Loss = 1.062486
Epoch 60: Loss = 1.004300
Epoch 80: Loss = 1.026375
Epoch 100: Loss = 1.104396
Epoch 120: Loss = 1.082884
Epoch 140: Loss = 1.033087
Epoch 160: Loss = 1.120570
Epoch 180: Loss = 1.038353
Epoch 200: Loss = 1.093677
Epoch 220: Loss = 1.095105
Epoch 240: Loss = 1.070632
Epoch 260: Loss = 1.091898
Epoch 280: Loss = 1.091521
[2;36m[22:01:18][0m[2;36m [0m[34mINFO    [0m LOCAL_RANK: [1;36m0[0m - CUDA_VISIBLE_DEVICES: [1m[[0m[1;36m0[0m,[1;36m1[0m,[1;36m2[0m,[1;36m3[0m[1m][0m                                                                                        [2mcuda.py:61[0m
[2;36m          [0m[2;36m [0m[34mINFO    [0m                                                                                                                              [2mmodel_summary.py:104[0m
[2;36m           [0m           | Name            | Type                | Params | Mode                                                                    [2m                    [0m
[2;36m           [0m         ----------------------------------------------------------------                                                             [2m                    [0m
[2;36m           [0m         [1;36m0[0m | GNNEnc          | FlexibleBackboneGNN | [1;36m20.5[0m K | train                                                                   [2m                    [0m
[2;36m           [0m         [1;36m1[0m | de              | DomainEmbedder      | [1;36m33.0[0m K | train                                                                   [2m                    [0m
[2;36m           [0m         [1;36m2[0m | frozen_backbone | BackboneGNN2        | [1;36m12.2[0m K | eval                                                                    [2m                    [0m
[2;36m           [0m         [1;36m3[0m | pama            | PAMA                | [1;36m25.1[0m K | train                                                                   [2m                    [0m
[2;36m           [0m         ----------------------------------------------------------------                                                             [2m                    [0m
[2;36m           [0m         [1;36m82.3[0m K    Trainable params                                                                                                   [2m                    [0m
[2;36m           [0m         [1;36m0[0m         Non-trainable params                                                                                               [2m                    [0m
[2;36m           [0m         [1;36m82.3[0m K    Total params                                                                                                       [2m                    [0m
[2;36m           [0m         [1;36m0.329[0m     Total estimated model params size [1m([0mMB[1m)[0m                                                                             [2m                    [0m
[2;36m           [0m         [1;36m35[0m        Modules in train mode                                                                                              [2m                    [0m
[2;36m           [0m         [1;36m9[0m         Modules in eval mode                                                                                               [2m                    [0m
Epoch 4: 100%|██████████████████████████████████████████████████| 1/1 [01:51<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.860, train_acc_step=0.186, train_loss_epoch=1.880, train_acc_epoch=0.177][2;36m[22:13:57][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved. New best score: [1;36m2.317[0m                                                                             [2mearly_stopping.py:273[0m
/home/zhuowei/anaconda3/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 3. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
Epoch 4: 100%|███████████████████| 1/1 [02:05<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.860, train_acc_step=0.186, train_loss_epoch=1.880, train_acc_epoch=0.177, val_loss=2.320, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4[0m, global step [1;36m5[0m: [32m'val_loss'[0m reached [1;36m2.31657[0m [1m([0mbest [1;36m2.31657[0m[1m)[0m, saving model to                                        [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m04[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m2[0m[32m.3166.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 9: 100%|███████████████████| 1/1 [01:41<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.850, train_acc_step=0.177, train_loss_epoch=1.850, train_acc_epoch=0.184, val_loss=2.320, val_acc=0.183][2;36m[22:22:41][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.170[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m2.147[0m                                               [2mearly_stopping.py:273[0m
Epoch 9: 100%|███████████████████| 1/1 [01:57<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.850, train_acc_step=0.177, train_loss_epoch=1.850, train_acc_epoch=0.184, val_loss=2.150, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m9[0m, global step [1;36m10[0m: [32m'val_loss'[0m reached [1;36m2.14655[0m [1m([0mbest [1;36m2.14655[0m[1m)[0m, saving model to                                       [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m09[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m2[0m[32m.1466.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 14: 100%|██████████████████| 1/1 [01:42<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.840, train_acc_step=0.178, train_loss_epoch=1.840, train_acc_epoch=0.182, val_loss=2.150, val_acc=0.183][2;36m[22:31:14][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.113[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m2.033[0m                                               [2mearly_stopping.py:273[0m
Epoch 14: 100%|██████████████████| 1/1 [01:54<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.840, train_acc_step=0.178, train_loss_epoch=1.840, train_acc_epoch=0.182, val_loss=2.030, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m14[0m, global step [1;36m15[0m: [32m'val_loss'[0m reached [1;36m2.03307[0m [1m([0mbest [1;36m2.03307[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m14[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m2[0m[32m.0331.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 19: 100%|██████████████████| 1/1 [00:27<00:00,  0.04it/s, v_num=qlut, train_loss_step=1.840, train_acc_step=0.177, train_loss_epoch=1.840, train_acc_epoch=0.184, val_loss=2.030, val_acc=0.183][2;36m[22:34:01][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.058[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.976[0m                                               [2mearly_stopping.py:273[0m
Epoch 19: 100%|██████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.840, train_acc_step=0.177, train_loss_epoch=1.840, train_acc_epoch=0.184, val_loss=1.980, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m19[0m, global step [1;36m20[0m: [32m'val_loss'[0m reached [1;36m1.97553[0m [1m([0mbest [1;36m1.97553[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m19[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.9755.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 24: 100%|██████████████████| 1/1 [00:27<00:00,  0.04it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.180, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.980, val_acc=0.183][2;36m[22:37:12][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.033[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.943[0m                                               [2mearly_stopping.py:273[0m
Epoch 24: 100%|██████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.180, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.940, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m24[0m, global step [1;36m25[0m: [32m'val_loss'[0m reached [1;36m1.94296[0m [1m([0mbest [1;36m1.94296[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m24[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.9430.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 29: 100%|██████████████████| 1/1 [00:47<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.192, train_loss_epoch=1.830, train_acc_epoch=0.182, val_loss=1.940, val_acc=0.183][2;36m[22:41:07][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.041[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.902[0m                                               [2mearly_stopping.py:273[0m
Epoch 29: 100%|██████████████████| 1/1 [00:54<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.192, train_loss_epoch=1.830, train_acc_epoch=0.182, val_loss=1.900, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m29[0m, global step [1;36m30[0m: [32m'val_loss'[0m reached [1;36m1.90219[0m [1m([0mbest [1;36m1.90219[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m29[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.9022.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 34: 100%|██████████████████| 1/1 [00:28<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.186, train_loss_epoch=1.830, train_acc_epoch=0.184, val_loss=1.900, val_acc=0.183][2;36m[22:43:44][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.018[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.884[0m                                               [2mearly_stopping.py:273[0m
Epoch 34: 100%|██████████████████| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.186, train_loss_epoch=1.830, train_acc_epoch=0.184, val_loss=1.880, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m34[0m, global step [1;36m35[0m: [32m'val_loss'[0m reached [1;36m1.88382[0m [1m([0mbest [1;36m1.88382[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m34[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8838.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 39: 100%|██████████████████| 1/1 [00:27<00:00,  0.04it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.179, train_loss_epoch=1.830, train_acc_epoch=0.175, val_loss=1.880, val_acc=0.183][2;36m[22:46:09][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.015[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.869[0m                                               [2mearly_stopping.py:273[0m
Epoch 39: 100%|██████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.179, train_loss_epoch=1.830, train_acc_epoch=0.175, val_loss=1.870, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m39[0m, global step [1;36m40[0m: [32m'val_loss'[0m reached [1;36m1.86874[0m [1m([0mbest [1;36m1.86874[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m39[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8687.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 44: 100%|██████████████████| 1/1 [00:27<00:00,  0.04it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.184, val_loss=1.870, val_acc=0.183][2;36m[22:48:34][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.005[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.864[0m                                               [2mearly_stopping.py:273[0m
Epoch 44: 100%|██████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.184, val_loss=1.860, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m44[0m, global step [1;36m45[0m: [32m'val_loss'[0m reached [1;36m1.86381[0m [1m([0mbest [1;36m1.86381[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m44[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8638.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 49: 100%|██████████████████| 1/1 [00:27<00:00,  0.04it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.179, train_loss_epoch=1.830, train_acc_epoch=0.181, val_loss=1.860, val_acc=0.183][2;36m[22:51:00][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.012[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.852[0m                                               [2mearly_stopping.py:273[0m
Epoch 49: 100%|██████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.179, train_loss_epoch=1.830, train_acc_epoch=0.181, val_loss=1.850, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m49[0m, global step [1;36m50[0m: [32m'val_loss'[0m reached [1;36m1.85218[0m [1m([0mbest [1;36m1.85218[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m49[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8522.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 54: 100%|██████████████████| 1/1 [00:27<00:00,  0.04it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.850, val_acc=0.183][2;36m[22:53:26][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.003[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.849[0m                                               [2mearly_stopping.py:273[0m
Epoch 54: 100%|██████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.850, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m54[0m, global step [1;36m55[0m: [32m'val_loss'[0m reached [1;36m1.84917[0m [1m([0mbest [1;36m1.84917[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m54[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8492.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 59: 100%|██████████████████| 1/1 [00:28<00:00,  0.04it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.850, val_acc=0.183][2;36m[22:55:51][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.006[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.843[0m                                               [2mearly_stopping.py:273[0m
Epoch 59: 100%|██████████████████| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.840, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m59[0m, global step [1;36m60[0m: [32m'val_loss'[0m reached [1;36m1.84342[0m [1m([0mbest [1;36m1.84342[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m59[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8434.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 64: 100%|██████████████████| 1/1 [00:27<00:00,  0.04it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, val_loss=1.840, val_acc=0.183][2;36m[22:58:17][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.003[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.841[0m                                               [2mearly_stopping.py:273[0m
Epoch 64: 100%|██████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, val_loss=1.840, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m64[0m, global step [1;36m65[0m: [32m'val_loss'[0m reached [1;36m1.84073[0m [1m([0mbest [1;36m1.84073[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m64[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8407.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 69: 100%|██████████████████| 1/1 [00:29<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.179, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.840, val_acc=0.183][2;36m[23:00:44][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.002[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.839[0m                                               [2mearly_stopping.py:273[0m
Epoch 69: 100%|██████████████████| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.179, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.840, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m69[0m, global step [1;36m70[0m: [32m'val_loss'[0m reached [1;36m1.83873[0m [1m([0mbest [1;36m1.83873[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m69[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8387.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 74: 100%|██████████████████| 1/1 [00:27<00:00,  0.04it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.840, val_acc=0.183][2;36m[23:03:09][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.003[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.836[0m                                               [2mearly_stopping.py:273[0m
Epoch 74: 100%|██████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.840, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m74[0m, global step [1;36m75[0m: [32m'val_loss'[0m reached [1;36m1.83616[0m [1m([0mbest [1;36m1.83616[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m74[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8362.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 79: 100%|██████████████████| 1/1 [00:28<00:00,  0.04it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.840, val_acc=0.183][2;36m[23:05:34][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.002[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.834[0m                                               [2mearly_stopping.py:273[0m
Epoch 79: 100%|██████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.830, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m79[0m, global step [1;36m80[0m: [32m'val_loss'[0m reached [1;36m1.83403[0m [1m([0mbest [1;36m1.83403[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m79[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8340.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 84: 100%|██████████████████| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.186, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.830, val_acc=0.183][2;36m[23:08:00][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m84[0m, global step [1;36m85[0m: [32m'val_loss'[0m reached [1;36m1.83333[0m [1m([0mbest [1;36m1.83333[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m84[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8333.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 89: 100%|██████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.182, val_loss=1.830, val_acc=0.183][2;36m[23:10:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m89[0m, global step [1;36m90[0m: [32m'val_loss'[0m reached [1;36m1.83326[0m [1m([0mbest [1;36m1.83326[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m89[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8333.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 94: 100%|██████████████████| 1/1 [00:28<00:00,  0.04it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.830, val_acc=0.183][2;36m[23:12:52][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.002[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.832[0m                                               [2mearly_stopping.py:273[0m
Epoch 94: 100%|██████████████████| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.830, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m94[0m, global step [1;36m95[0m: [32m'val_loss'[0m reached [1;36m1.83232[0m [1m([0mbest [1;36m1.83232[0m[1m)[0m, saving model to                                      [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m94[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8323.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 99: 100%|██████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.182, val_loss=1.830, val_acc=0.183][2;36m[23:15:16][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m99[0m, global step [1;36m100[0m: [32m'val_loss'[0m reached [1;36m1.83155[0m [1m([0mbest [1;36m1.83155[0m[1m)[0m, saving model to                                     [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m99[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8316.ckpt'[0m as top [1;36m3[0m                                                                                       [2m                       [0m
Epoch 104: 100%|█████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.182, val_loss=1.830, val_acc=0.183][2;36m[23:17:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m104[0m, global step [1;36m105[0m: [32m'val_loss'[0m reached [1;36m1.83174[0m [1m([0mbest [1;36m1.83155[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m104[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8317.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 109: 100%|█████████████████| 1/1 [00:27<00:00,  0.04it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, val_loss=1.830, val_acc=0.183][2;36m[23:20:08][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.001[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.831[0m                                               [2mearly_stopping.py:273[0m
Epoch 109: 100%|█████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, val_loss=1.830, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m109[0m, global step [1;36m110[0m: [32m'val_loss'[0m reached [1;36m1.83088[0m [1m([0mbest [1;36m1.83088[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m109[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8309.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 114: 100%|█████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.830, val_acc=0.183][2;36m[23:22:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m114[0m, global step [1;36m115[0m: [32m'val_loss'[0m reached [1;36m1.83031[0m [1m([0mbest [1;36m1.83031[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m114[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8303.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 119: 100%|█████████████████| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.182, val_loss=1.830, val_acc=0.183][2;36m[23:24:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m119[0m, global step [1;36m120[0m: [32m'val_loss'[0m reached [1;36m1.83009[0m [1m([0mbest [1;36m1.83009[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m119[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8301.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 124: 100%|█████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.184, val_loss=1.830, val_acc=0.183][2;36m[23:27:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m124[0m, global step [1;36m125[0m: [32m'val_loss'[0m reached [1;36m1.83006[0m [1m([0mbest [1;36m1.83006[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m124[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8301.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 129: 100%|█████████████████| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.830, val_acc=0.183][2;36m[23:29:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m129[0m, global step [1;36m130[0m: [32m'val_loss'[0m reached [1;36m1.83004[0m [1m([0mbest [1;36m1.83004[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m129[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8300.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 134: 100%|█████████████████| 1/1 [00:27<00:00,  0.04it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.185, val_loss=1.830, val_acc=0.183][2;36m[23:32:15][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.001[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.830[0m                                               [2mearly_stopping.py:273[0m
Epoch 134: 100%|█████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.185, val_loss=1.830, val_acc=0.183][2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m134[0m, global step [1;36m135[0m: [32m'val_loss'[0m reached [1;36m1.82957[0m [1m([0mbest [1;36m1.82957[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m134[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8296.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 139: 100%|█████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.186, val_loss=1.830, val_acc=0.183][2;36m[23:34:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m139[0m, global step [1;36m140[0m: [32m'val_loss'[0m reached [1;36m1.82926[0m [1m([0mbest [1;36m1.82926[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m139[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8293.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 144: 100%|█████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, val_loss=1.830, val_acc=0.183][2;36m[23:37:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m144[0m, global step [1;36m145[0m: [32m'val_loss'[0m reached [1;36m1.82957[0m [1m([0mbest [1;36m1.82926[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m144[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8296.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 149: 100%|█████████████████| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.179, train_loss_epoch=1.830, train_acc_epoch=0.182, val_loss=1.830, val_acc=0.183][2;36m[23:39:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m149[0m, global step [1;36m150[0m: [32m'val_loss'[0m reached [1;36m1.82924[0m [1m([0mbest [1;36m1.82924[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m149[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8292.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 154: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[23:41:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m154[0m, global step [1;36m155[0m: [32m'val_loss'[0m reached [1;36m1.82929[0m [1m([0mbest [1;36m1.82924[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m154[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8293.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 159: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[23:44:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m159[0m, global step [1;36m160[0m: [32m'val_loss'[0m reached [1;36m1.82901[0m [1m([0mbest [1;36m1.82901[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m159[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8290.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 164: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.185, [2;36m[23:46:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m164[0m, global step [1;36m165[0m: [32m'val_loss'[0m reached [1;36m1.82897[0m [1m([0mbest [1;36m1.82897[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m164[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8290.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 169: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.186, [2;36m[23:49:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m169[0m, global step [1;36m170[0m: [32m'val_loss'[0m reached [1;36m1.82914[0m [1m([0mbest [1;36m1.82897[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m169[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8291.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 174: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[23:51:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m174[0m, global step [1;36m175[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 179: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[23:54:07][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m179[0m, global step [1;36m180[0m: [32m'val_loss'[0m reached [1;36m1.82872[0m [1m([0mbest [1;36m1.82872[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m179[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8287.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 184: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[23:56:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m184[0m, global step [1;36m185[0m: [32m'val_loss'[0m reached [1;36m1.82895[0m [1m([0mbest [1;36m1.82872[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m184[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8289.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 189: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[23:58:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m189[0m, global step [1;36m190[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 194: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.186, train_loss_epoch=1.830, train_acc_epoch=0.182, [2;36m[00:01:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m194[0m, global step [1;36m195[0m: [32m'val_loss'[0m reached [1;36m1.82865[0m [1m([0mbest [1;36m1.82865[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m194[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8287.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 199: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[00:03:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m199[0m, global step [1;36m200[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 204: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[00:06:16][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m204[0m, global step [1;36m205[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 209: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[00:08:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m209[0m, global step [1;36m210[0m: [32m'val_loss'[0m reached [1;36m1.82884[0m [1m([0mbest [1;36m1.82865[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m209[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8288.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 214: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[00:11:07][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m214[0m, global step [1;36m215[0m: [32m'val_loss'[0m reached [1;36m1.82861[0m [1m([0mbest [1;36m1.82861[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m214[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8286.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 219: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[00:13:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m219[0m, global step [1;36m220[0m: [32m'val_loss'[0m reached [1;36m1.82868[0m [1m([0mbest [1;36m1.82861[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m219[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8287.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 224: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[00:15:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m224[0m, global step [1;36m225[0m: [32m'val_loss'[0m reached [1;36m1.82861[0m [1m([0mbest [1;36m1.82861[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m224[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8286.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 229: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[00:18:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m229[0m, global step [1;36m230[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 234: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.182, [2;36m[00:20:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m234[0m, global step [1;36m235[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 239: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[00:23:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m239[0m, global step [1;36m240[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 244: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[00:25:39][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m244[0m, global step [1;36m245[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 249: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[00:28:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m249[0m, global step [1;36m250[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 254: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.182, [2;36m[00:30:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m254[0m, global step [1;36m255[0m: [32m'val_loss'[0m reached [1;36m1.82865[0m [1m([0mbest [1;36m1.82861[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m254[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8286.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 259: 100%|█| 1/1 [00:27<00:00,  0.04it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[00:32:58][0m[2;36m [0m[34mINFO    [0m Metric val_loss improved by [1;36m0.001[0m >= min_delta = [1;36m0.001[0m. New best score: [1;36m1.829[0m                                               [2mearly_stopping.py:273[0m
Epoch 259: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m          [0m[2;36m [0m[34mINFO    [0m Epoch [1;36m259[0m, global step [1;36m260[0m: [32m'val_loss'[0m reached [1;36m1.82854[0m [1m([0mbest [1;36m1.82854[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m259[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8285.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 264: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[00:35:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m264[0m, global step [1;36m265[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 269: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[00:37:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m269[0m, global step [1;36m270[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 274: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[00:40:16][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m274[0m, global step [1;36m275[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 279: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[00:42:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m279[0m, global step [1;36m280[0m: [32m'val_loss'[0m reached [1;36m1.82860[0m [1m([0mbest [1;36m1.82854[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m279[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8286.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 284: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[00:45:07][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m284[0m, global step [1;36m285[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 289: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[00:47:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m289[0m, global step [1;36m290[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 294: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[00:49:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m294[0m, global step [1;36m295[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 299: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.186, train_loss_epoch=1.830, train_acc_epoch=0.182, [2;36m[00:52:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m299[0m, global step [1;36m300[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 304: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.181, train_loss_epoch=1.830, train_acc_epoch=0.185, [2;36m[00:54:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m304[0m, global step [1;36m305[0m: [32m'val_loss'[0m reached [1;36m1.82855[0m [1m([0mbest [1;36m1.82854[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m304[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8285.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 309: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[00:57:16][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m309[0m, global step [1;36m310[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 314: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[00:59:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m314[0m, global step [1;36m315[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 319: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.187, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[01:02:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m319[0m, global step [1;36m320[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 324: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.182, [2;36m[01:04:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m324[0m, global step [1;36m325[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 329: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.185, [2;36m[01:07:00][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m329[0m, global step [1;36m330[0m: [32m'val_loss'[0m reached [1;36m1.82851[0m [1m([0mbest [1;36m1.82851[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m329[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8285.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 334: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.176, [2;36m[01:09:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m334[0m, global step [1;36m335[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 339: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.186, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[01:11:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m339[0m, global step [1;36m340[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 344: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[01:14:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m344[0m, global step [1;36m345[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 349: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[01:16:44][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m349[0m, global step [1;36m350[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 354: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[01:19:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m354[0m, global step [1;36m355[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 359: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.186, [2;36m[01:21:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m359[0m, global step [1;36m360[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 364: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[01:24:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m364[0m, global step [1;36m365[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 369: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.186, train_loss_epoch=1.830, train_acc_epoch=0.187, [2;36m[01:26:28][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m369[0m, global step [1;36m370[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 374: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[01:28:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m374[0m, global step [1;36m375[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 379: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.185, [2;36m[01:31:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m379[0m, global step [1;36m380[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 384: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.181, train_loss_epoch=1.830, train_acc_epoch=0.185, [2;36m[01:33:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m384[0m, global step [1;36m385[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 389: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.185, [2;36m[01:36:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m389[0m, global step [1;36m390[0m: [32m'val_loss'[0m reached [1;36m1.82850[0m [1m([0mbest [1;36m1.82850[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m389[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8285.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 394: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[01:38:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m394[0m, global step [1;36m395[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 399: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.181, [2;36m[01:41:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m399[0m, global step [1;36m400[0m: [32m'val_loss'[0m reached [1;36m1.82848[0m [1m([0mbest [1;36m1.82848[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m399[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8285.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 404: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[01:43:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m404[0m, global step [1;36m405[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 409: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[01:46:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m409[0m, global step [1;36m410[0m: [32m'val_loss'[0m reached [1;36m1.82848[0m [1m([0mbest [1;36m1.82848[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m409[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8285.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 414: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[01:48:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m414[0m, global step [1;36m415[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 419: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[01:50:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m419[0m, global step [1;36m420[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 424: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.182, [2;36m[01:53:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m424[0m, global step [1;36m425[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 429: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.185, [2;36m[01:55:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m429[0m, global step [1;36m430[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 434: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[01:58:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m434[0m, global step [1;36m435[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 439: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.180, [2;36m[02:00:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m439[0m, global step [1;36m440[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 444: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[02:03:00][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m444[0m, global step [1;36m445[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 449: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[02:05:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m449[0m, global step [1;36m450[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 454: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.182, [2;36m[02:07:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m454[0m, global step [1;36m455[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 459: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.182, [2;36m[02:10:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m459[0m, global step [1;36m460[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 464: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[02:12:44][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m464[0m, global step [1;36m465[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 469: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.185, [2;36m[02:15:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m469[0m, global step [1;36m470[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 474: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[02:17:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m474[0m, global step [1;36m475[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 479: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[02:20:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m479[0m, global step [1;36m480[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 484: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.182, [2;36m[02:22:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m484[0m, global step [1;36m485[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 489: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.194, [2;36m[02:24:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m489[0m, global step [1;36m490[0m: [32m'val_loss'[0m reached [1;36m1.82850[0m [1m([0mbest [1;36m1.82848[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m489[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8285.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 494: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[02:27:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m494[0m, global step [1;36m495[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 499: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[02:29:44][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m499[0m, global step [1;36m500[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 504: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.190, train_loss_epoch=1.830, train_acc_epoch=0.185, [2;36m[02:32:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m504[0m, global step [1;36m505[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 509: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[02:34:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m509[0m, global step [1;36m510[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 514: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.188, [2;36m[02:37:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m514[0m, global step [1;36m515[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 519: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[02:39:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m519[0m, global step [1;36m520[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 524: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[02:41:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m524[0m, global step [1;36m525[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 529: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.178, train_loss_epoch=1.830, train_acc_epoch=0.177, [2;36m[02:44:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m529[0m, global step [1;36m530[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 534: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.186, [2;36m[02:46:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m534[0m, global step [1;36m535[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 539: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.181, [2;36m[02:49:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m539[0m, global step [1;36m540[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 544: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[02:51:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m544[0m, global step [1;36m545[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 549: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.186, [2;36m[02:53:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m549[0m, global step [1;36m550[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 554: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[02:56:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m554[0m, global step [1;36m555[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 559: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[02:58:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m559[0m, global step [1;36m560[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 564: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[03:01:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m564[0m, global step [1;36m565[0m: [32m'val_loss'[0m reached [1;36m1.82849[0m [1m([0mbest [1;36m1.82848[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m564[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8285.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 569: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[03:03:39][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m569[0m, global step [1;36m570[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 574: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.181, [2;36m[03:06:07][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m574[0m, global step [1;36m575[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 579: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[03:08:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m579[0m, global step [1;36m580[0m: [32m'val_loss'[0m reached [1;36m1.82849[0m [1m([0mbest [1;36m1.82848[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m579[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8285.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 584: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[03:10:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m584[0m, global step [1;36m585[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 589: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[03:13:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m589[0m, global step [1;36m590[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 594: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[03:15:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m594[0m, global step [1;36m595[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 599: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[03:18:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m599[0m, global step [1;36m600[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 604: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[03:20:44][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m604[0m, global step [1;36m605[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 609: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.181, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[03:23:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m609[0m, global step [1;36m610[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 614: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[03:25:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m614[0m, global step [1;36m615[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 619: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[03:28:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m619[0m, global step [1;36m620[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 624: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[03:30:28][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m624[0m, global step [1;36m625[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 629: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[03:32:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m629[0m, global step [1;36m630[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 634: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[03:35:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m634[0m, global step [1;36m635[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 639: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[03:37:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m639[0m, global step [1;36m640[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 644: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[03:40:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m644[0m, global step [1;36m645[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 649: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[03:42:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m649[0m, global step [1;36m650[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 654: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[03:45:02][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m654[0m, global step [1;36m655[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 659: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.181, [2;36m[03:47:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m659[0m, global step [1;36m660[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 664: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[03:49:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m664[0m, global step [1;36m665[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 669: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[03:52:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m669[0m, global step [1;36m670[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 674: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[03:54:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m674[0m, global step [1;36m675[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 679: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[03:57:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m679[0m, global step [1;36m680[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 684: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[03:59:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m684[0m, global step [1;36m685[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 689: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:02:00][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m689[0m, global step [1;36m690[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 694: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:04:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m694[0m, global step [1;36m695[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 699: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:06:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m699[0m, global step [1;36m700[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 704: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:09:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m704[0m, global step [1;36m705[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 709: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:11:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m709[0m, global step [1;36m710[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 714: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.185, [2;36m[04:14:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m714[0m, global step [1;36m715[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 719: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[04:16:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m719[0m, global step [1;36m720[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 724: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:19:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m724[0m, global step [1;36m725[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 729: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:21:28][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m729[0m, global step [1;36m730[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 734: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:23:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m734[0m, global step [1;36m735[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 739: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:26:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m739[0m, global step [1;36m740[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 744: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:28:44][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m744[0m, global step [1;36m745[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 749: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[04:31:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m749[0m, global step [1;36m750[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 754: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:33:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m754[0m, global step [1;36m755[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 759: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:36:02][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m759[0m, global step [1;36m760[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 764: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:38:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m764[0m, global step [1;36m765[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 769: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:40:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m769[0m, global step [1;36m770[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 774: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:43:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m774[0m, global step [1;36m775[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 779: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.182, [2;36m[04:45:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m779[0m, global step [1;36m780[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 784: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:48:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m784[0m, global step [1;36m785[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 789: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:50:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m789[0m, global step [1;36m790[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 794: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[04:52:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m794[0m, global step [1;36m795[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 799: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[04:55:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m799[0m, global step [1;36m800[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 804: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[04:57:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m804[0m, global step [1;36m805[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 809: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[05:00:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m809[0m, global step [1;36m810[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 814: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[05:02:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m814[0m, global step [1;36m815[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 819: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[05:05:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m819[0m, global step [1;36m820[0m: [32m'val_loss'[0m reached [1;36m1.82841[0m [1m([0mbest [1;36m1.82841[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m819[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 824: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[05:07:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m824[0m, global step [1;36m825[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 829: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[05:09:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m829[0m, global step [1;36m830[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 834: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[05:12:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m834[0m, global step [1;36m835[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 839: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[05:14:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m839[0m, global step [1;36m840[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 844: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[05:17:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m844[0m, global step [1;36m845[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 849: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[05:19:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m849[0m, global step [1;36m850[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 854: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[05:22:07][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m854[0m, global step [1;36m855[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 859: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.185, [2;36m[05:24:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m859[0m, global step [1;36m860[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 864: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[05:26:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m864[0m, global step [1;36m865[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 869: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[05:29:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m869[0m, global step [1;36m870[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 874: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[05:31:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m874[0m, global step [1;36m875[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 879: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.187, train_loss_epoch=1.830, train_acc_epoch=0.182, [2;36m[05:34:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m879[0m, global step [1;36m880[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 884: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.180, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[05:36:39][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m884[0m, global step [1;36m885[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 889: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.180, [2;36m[05:39:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m889[0m, global step [1;36m890[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 894: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.185, [2;36m[05:41:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m894[0m, global step [1;36m895[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 899: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.182, [2;36m[05:43:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m899[0m, global step [1;36m900[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 904: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.186, [2;36m[05:46:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m904[0m, global step [1;36m905[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 909: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.186, train_loss_epoch=1.830, train_acc_epoch=0.189, [2;36m[05:48:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m909[0m, global step [1;36m910[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 914: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.181, [2;36m[05:51:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m914[0m, global step [1;36m915[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 919: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[05:53:44][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m919[0m, global step [1;36m920[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 924: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[05:56:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m924[0m, global step [1;36m925[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 929: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[05:58:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m929[0m, global step [1;36m930[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 934: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[06:01:02][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m934[0m, global step [1;36m935[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 939: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184, [2;36m[06:03:28][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m939[0m, global step [1;36m940[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 944: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.186, [2;36m[06:05:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m944[0m, global step [1;36m945[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 949: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[06:08:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m949[0m, global step [1;36m950[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 954: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.186, [2;36m[06:10:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m954[0m, global step [1;36m955[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 959: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.185, [2;36m[06:13:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m959[0m, global step [1;36m960[0m: [32m'val_loss'[0m reached [1;36m1.82845[0m [1m([0mbest [1;36m1.82841[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m959[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8285.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 964: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.182, [2;36m[06:15:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m964[0m, global step [1;36m965[0m: [32m'val_loss'[0m reached [1;36m1.82847[0m [1m([0mbest [1;36m1.82841[0m[1m)[0m, saving model to                                    [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m964[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8285.ckpt'[0m as top [1;36m3[0m                                                                                      [2m                       [0m
Epoch 969: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.186, train_loss_epoch=1.830, train_acc_epoch=0.186, [2;36m[06:18:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m969[0m, global step [1;36m970[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 974: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[06:20:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m974[0m, global step [1;36m975[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 979: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.186, [2;36m[06:22:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m979[0m, global step [1;36m980[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 984: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[06:25:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m984[0m, global step [1;36m985[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 989: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[06:27:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m989[0m, global step [1;36m990[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 994: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[06:30:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m994[0m, global step [1;36m995[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                   [2mmodel_checkpoint.py:709[0m
Epoch 999: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183, [2;36m[06:32:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m999[0m, global step [1;36m1000[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                  [2mmodel_checkpoint.py:709[0m
Epoch 1004: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[06:35:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1004[0m, global step [1;36m1005[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1009: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:37:28][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1009[0m, global step [1;36m1010[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1014: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:39:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1014[0m, global step [1;36m1015[0m: [32m'val_loss'[0m reached [1;36m1.82846[0m [1m([0mbest [1;36m1.82841[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m1014[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8285.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 1019: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:42:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1019[0m, global step [1;36m1020[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1024: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:44:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1024[0m, global step [1;36m1025[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1029: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:47:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1029[0m, global step [1;36m1030[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1034: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:49:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1034[0m, global step [1;36m1035[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1039: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:52:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1039[0m, global step [1;36m1040[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1044: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:54:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1044[0m, global step [1;36m1045[0m: [32m'val_loss'[0m reached [1;36m1.82845[0m [1m([0mbest [1;36m1.82841[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m1044[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 1049: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[06:56:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1049[0m, global step [1;36m1050[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1054: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:59:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1054[0m, global step [1;36m1055[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1059: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:01:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1059[0m, global step [1;36m1060[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1064: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:04:13][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1064[0m, global step [1;36m1065[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1069: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:06:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1069[0m, global step [1;36m1070[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1074: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:09:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1074[0m, global step [1;36m1075[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1079: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:11:30][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1079[0m, global step [1;36m1080[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1084: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[07:13:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1084[0m, global step [1;36m1085[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1089: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:16:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1089[0m, global step [1;36m1090[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1094: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[07:18:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1094[0m, global step [1;36m1095[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1099: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:21:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1099[0m, global step [1;36m1100[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1104: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:23:40][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1104[0m, global step [1;36m1105[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1109: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[07:26:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1109[0m, global step [1;36m1110[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1114: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.186,[2;36m[07:28:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1114[0m, global step [1;36m1115[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1119: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:30:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1119[0m, global step [1;36m1120[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1124: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:33:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1124[0m, global step [1;36m1125[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1129: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[07:35:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1129[0m, global step [1;36m1130[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1134: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:38:16][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1134[0m, global step [1;36m1135[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1139: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:40:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1139[0m, global step [1;36m1140[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1144: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:43:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1144[0m, global step [1;36m1145[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1149: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[07:45:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1149[0m, global step [1;36m1150[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1154: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.185,[2;36m[07:47:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1154[0m, global step [1;36m1155[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1159: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.181,[2;36m[07:50:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1159[0m, global step [1;36m1160[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1164: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:52:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1164[0m, global step [1;36m1165[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1169: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:55:16][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1169[0m, global step [1;36m1170[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1174: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:57:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1174[0m, global step [1;36m1175[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1179: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:00:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1179[0m, global step [1;36m1180[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1184: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:02:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1184[0m, global step [1;36m1185[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1189: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[08:05:00][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1189[0m, global step [1;36m1190[0m: [32m'val_loss'[0m reached [1;36m1.82845[0m [1m([0mbest [1;36m1.82841[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m1189[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8285.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 1194: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:07:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1194[0m, global step [1;36m1195[0m: [32m'val_loss'[0m reached [1;36m1.82839[0m [1m([0mbest [1;36m1.82839[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m1194[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 1199: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:09:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1199[0m, global step [1;36m1200[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1204: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:12:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1204[0m, global step [1;36m1205[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1209: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[08:14:44][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1209[0m, global step [1;36m1210[0m: [32m'val_loss'[0m reached [1;36m1.82841[0m [1m([0mbest [1;36m1.82839[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m1209[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 1214: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:17:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1214[0m, global step [1;36m1215[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1219: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[08:19:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1219[0m, global step [1;36m1220[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1224: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:22:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1224[0m, global step [1;36m1225[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1229: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[08:24:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1229[0m, global step [1;36m1230[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1234: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:26:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1234[0m, global step [1;36m1235[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1239: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:29:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1239[0m, global step [1;36m1240[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1244: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:31:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1244[0m, global step [1;36m1245[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1249: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:34:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1249[0m, global step [1;36m1250[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1254: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:36:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1254[0m, global step [1;36m1255[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1259: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.185,[2;36m[08:39:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1259[0m, global step [1;36m1260[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1264: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[08:41:28][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1264[0m, global step [1;36m1265[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1269: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:43:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1269[0m, global step [1;36m1270[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1274: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:46:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1274[0m, global step [1;36m1275[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1279: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:48:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1279[0m, global step [1;36m1280[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1284: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:51:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1284[0m, global step [1;36m1285[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1289: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:53:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1289[0m, global step [1;36m1290[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1294: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:56:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1294[0m, global step [1;36m1295[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1299: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.178, train_loss_epoch=1.830, train_acc_epoch=0.181,[2;36m[08:58:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1299[0m, global step [1;36m1300[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1304: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.182,[2;36m[09:01:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1304[0m, global step [1;36m1305[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1309: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:03:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1309[0m, global step [1;36m1310[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1314: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[09:06:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1314[0m, global step [1;36m1315[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1319: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[09:08:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1319[0m, global step [1;36m1320[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1324: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.182,[2;36m[09:11:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1324[0m, global step [1;36m1325[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1329: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[09:13:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1329[0m, global step [1;36m1330[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1334: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:16:00][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1334[0m, global step [1;36m1335[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1339: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.185,[2;36m[09:18:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1339[0m, global step [1;36m1340[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1344: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.181,[2;36m[09:20:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1344[0m, global step [1;36m1345[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1349: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[09:23:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1349[0m, global step [1;36m1350[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1354: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:25:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1354[0m, global step [1;36m1355[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1359: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:28:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1359[0m, global step [1;36m1360[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1364: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:30:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1364[0m, global step [1;36m1365[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1369: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:33:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1369[0m, global step [1;36m1370[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1374: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:35:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1374[0m, global step [1;36m1375[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1379: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.181,[2;36m[09:37:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1379[0m, global step [1;36m1380[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1384: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:40:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1384[0m, global step [1;36m1385[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1389: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[09:42:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1389[0m, global step [1;36m1390[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1394: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.185,[2;36m[09:45:13][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1394[0m, global step [1;36m1395[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1399: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:47:39][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1399[0m, global step [1;36m1400[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1404: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.186, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:50:05][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1404[0m, global step [1;36m1405[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1409: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[09:52:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1409[0m, global step [1;36m1410[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1414: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.182,[2;36m[09:54:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1414[0m, global step [1;36m1415[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1419: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.186, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:57:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1419[0m, global step [1;36m1420[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1424: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:59:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1424[0m, global step [1;36m1425[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1429: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:02:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1429[0m, global step [1;36m1430[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1434: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:04:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1434[0m, global step [1;36m1435[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1439: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.179, train_loss_epoch=1.830, train_acc_epoch=0.181,[2;36m[10:07:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1439[0m, global step [1;36m1440[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1444: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.182,[2;36m[10:09:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1444[0m, global step [1;36m1445[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1449: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:12:00][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1449[0m, global step [1;36m1450[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1454: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:14:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1454[0m, global step [1;36m1455[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1459: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:16:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1459[0m, global step [1;36m1460[0m: [32m'val_loss'[0m reached [1;36m1.82841[0m [1m([0mbest [1;36m1.82839[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m1459[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 1464: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:19:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1464[0m, global step [1;36m1465[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1469: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:21:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1469[0m, global step [1;36m1470[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1474: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:24:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1474[0m, global step [1;36m1475[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1479: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:26:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1479[0m, global step [1;36m1480[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1484: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[10:29:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1484[0m, global step [1;36m1485[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1489: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[10:31:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1489[0m, global step [1;36m1490[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1494: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.182,[2;36m[10:33:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1494[0m, global step [1;36m1495[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1499: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[10:36:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1499[0m, global step [1;36m1500[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1504: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.186,[2;36m[10:38:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1504[0m, global step [1;36m1505[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1509: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.175, train_loss_epoch=1.830, train_acc_epoch=0.185,[2;36m[10:41:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1509[0m, global step [1;36m1510[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1514: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.182,[2;36m[10:43:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1514[0m, global step [1;36m1515[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1519: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:46:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1519[0m, global step [1;36m1520[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1524: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:48:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1524[0m, global step [1;36m1525[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1529: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:51:00][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1529[0m, global step [1;36m1530[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1534: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:53:28][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1534[0m, global step [1;36m1535[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1539: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:55:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1539[0m, global step [1;36m1540[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1544: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:58:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1544[0m, global step [1;36m1545[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1549: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:00:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1549[0m, global step [1;36m1550[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1554: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.185,[2;36m[11:03:13][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1554[0m, global step [1;36m1555[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1559: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:05:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1559[0m, global step [1;36m1560[0m: [32m'val_loss'[0m reached [1;36m1.82838[0m [1m([0mbest [1;36m1.82838[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m1559[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 1564: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:08:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1564[0m, global step [1;36m1565[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1569: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:10:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1569[0m, global step [1;36m1570[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1574: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:12:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1574[0m, global step [1;36m1575[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1579: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:15:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1579[0m, global step [1;36m1580[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1584: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:17:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1584[0m, global step [1;36m1585[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1589: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:20:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1589[0m, global step [1;36m1590[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1594: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:22:40][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1594[0m, global step [1;36m1595[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1599: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[11:25:05][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1599[0m, global step [1;36m1600[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1604: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:27:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1604[0m, global step [1;36m1605[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1609: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:29:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1609[0m, global step [1;36m1610[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1614: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[11:32:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1614[0m, global step [1;36m1615[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1619: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:34:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1619[0m, global step [1;36m1620[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1624: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:37:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1624[0m, global step [1;36m1625[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1629: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:39:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1629[0m, global step [1;36m1630[0m: [32m'val_loss'[0m reached [1;36m1.82840[0m [1m([0mbest [1;36m1.82838[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m1629[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 1634: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:42:05][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1634[0m, global step [1;36m1635[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1639: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:44:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1639[0m, global step [1;36m1640[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1644: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:46:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1644[0m, global step [1;36m1645[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1649: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:49:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1649[0m, global step [1;36m1650[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1654: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:51:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1654[0m, global step [1;36m1655[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1659: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:54:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1659[0m, global step [1;36m1660[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1664: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:56:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1664[0m, global step [1;36m1665[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1669: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:59:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1669[0m, global step [1;36m1670[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1674: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:01:30][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1674[0m, global step [1;36m1675[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1679: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:03:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1679[0m, global step [1;36m1680[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1684: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[12:06:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1684[0m, global step [1;36m1685[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1689: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:08:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1689[0m, global step [1;36m1690[0m: [32m'val_loss'[0m reached [1;36m1.82840[0m [1m([0mbest [1;36m1.82838[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m1689[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 1694: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:11:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1694[0m, global step [1;36m1695[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1699: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:13:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1699[0m, global step [1;36m1700[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1704: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:16:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1704[0m, global step [1;36m1705[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1709: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.182,[2;36m[12:18:28][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1709[0m, global step [1;36m1710[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1714: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[12:20:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1714[0m, global step [1;36m1715[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1719: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:23:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1719[0m, global step [1;36m1720[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1724: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:25:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1724[0m, global step [1;36m1725[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1729: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.182,[2;36m[12:28:13][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1729[0m, global step [1;36m1730[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1734: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:30:38][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1734[0m, global step [1;36m1735[0m: [32m'val_loss'[0m reached [1;36m1.82836[0m [1m([0mbest [1;36m1.82836[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m1734[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 1739: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:33:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1739[0m, global step [1;36m1740[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1744: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:35:28][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1744[0m, global step [1;36m1745[0m: [32m'val_loss'[0m reached [1;36m1.82838[0m [1m([0mbest [1;36m1.82836[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m1744[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 1749: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:37:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1749[0m, global step [1;36m1750[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1754: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:40:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1754[0m, global step [1;36m1755[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1759: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:42:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1759[0m, global step [1;36m1760[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1764: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:45:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1764[0m, global step [1;36m1765[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1769: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:47:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1769[0m, global step [1;36m1770[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1774: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:50:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1774[0m, global step [1;36m1775[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1779: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:52:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1779[0m, global step [1;36m1780[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1784: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:55:00][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1784[0m, global step [1;36m1785[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1789: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:57:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1789[0m, global step [1;36m1790[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1794: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:59:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1794[0m, global step [1;36m1795[0m: [32m'val_loss'[0m reached [1;36m1.82838[0m [1m([0mbest [1;36m1.82836[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m1794[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 1799: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:02:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1799[0m, global step [1;36m1800[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1804: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:04:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1804[0m, global step [1;36m1805[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1809: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[13:07:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1809[0m, global step [1;36m1810[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1814: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:09:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1814[0m, global step [1;36m1815[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1819: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[13:12:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1819[0m, global step [1;36m1820[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1824: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:14:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1824[0m, global step [1;36m1825[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1829: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:16:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1829[0m, global step [1;36m1830[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1834: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:19:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1834[0m, global step [1;36m1835[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1839: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[13:21:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1839[0m, global step [1;36m1840[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1844: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:24:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1844[0m, global step [1;36m1845[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1849: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:26:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1849[0m, global step [1;36m1850[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1854: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:29:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1854[0m, global step [1;36m1855[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1859: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:31:30][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1859[0m, global step [1;36m1860[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1864: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:33:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1864[0m, global step [1;36m1865[0m: [32m'val_loss'[0m reached [1;36m1.82836[0m [1m([0mbest [1;36m1.82836[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m1864[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 1869: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:36:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1869[0m, global step [1;36m1870[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1874: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:38:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1874[0m, global step [1;36m1875[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1879: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:41:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1879[0m, global step [1;36m1880[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1884: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[13:43:39][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1884[0m, global step [1;36m1885[0m: [32m'val_loss'[0m reached [1;36m1.82838[0m [1m([0mbest [1;36m1.82836[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m1884[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 1889: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:46:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1889[0m, global step [1;36m1890[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1894: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:48:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1894[0m, global step [1;36m1895[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1899: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:50:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1899[0m, global step [1;36m1900[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1904: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.180,[2;36m[13:53:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1904[0m, global step [1;36m1905[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1909: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:55:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1909[0m, global step [1;36m1910[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1914: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[13:58:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1914[0m, global step [1;36m1915[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1919: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:00:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1919[0m, global step [1;36m1920[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1924: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:03:02][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1924[0m, global step [1;36m1925[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1929: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:05:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1929[0m, global step [1;36m1930[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1934: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:07:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1934[0m, global step [1;36m1935[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1939: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.186,[2;36m[14:10:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1939[0m, global step [1;36m1940[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1944: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.182,[2;36m[14:12:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1944[0m, global step [1;36m1945[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1949: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:15:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1949[0m, global step [1;36m1950[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1954: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:17:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1954[0m, global step [1;36m1955[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1959: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:20:02][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1959[0m, global step [1;36m1960[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1964: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:22:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1964[0m, global step [1;36m1965[0m: [32m'val_loss'[0m reached [1;36m1.82837[0m [1m([0mbest [1;36m1.82836[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m1964[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 1969: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:24:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1969[0m, global step [1;36m1970[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1974: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:27:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1974[0m, global step [1;36m1975[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1979: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:29:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1979[0m, global step [1;36m1980[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1984: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:32:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1984[0m, global step [1;36m1985[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1989: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:34:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1989[0m, global step [1;36m1990[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1994: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:37:07][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1994[0m, global step [1;36m1995[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 1999: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:39:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m1999[0m, global step [1;36m2000[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2004: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:41:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2004[0m, global step [1;36m2005[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2009: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:44:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2009[0m, global step [1;36m2010[0m: [32m'val_loss'[0m reached [1;36m1.82837[0m [1m([0mbest [1;36m1.82836[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2009[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2014: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:46:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2014[0m, global step [1;36m2015[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2019: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:49:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2019[0m, global step [1;36m2020[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2024: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[14:51:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2024[0m, global step [1;36m2025[0m: [32m'val_loss'[0m reached [1;36m1.82836[0m [1m([0mbest [1;36m1.82836[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2024[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2029: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[14:54:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2029[0m, global step [1;36m2030[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2034: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:56:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2034[0m, global step [1;36m2035[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2039: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:58:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2039[0m, global step [1;36m2040[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2044: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:01:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2044[0m, global step [1;36m2045[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2049: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:03:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2049[0m, global step [1;36m2050[0m: [32m'val_loss'[0m reached [1;36m1.82836[0m [1m([0mbest [1;36m1.82836[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2049[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2054: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:06:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2054[0m, global step [1;36m2055[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2059: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:08:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2059[0m, global step [1;36m2060[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2064: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[15:11:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2064[0m, global step [1;36m2065[0m: [32m'val_loss'[0m reached [1;36m1.82835[0m [1m([0mbest [1;36m1.82835[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2064[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2069: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[15:13:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2069[0m, global step [1;36m2070[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2074: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:15:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2074[0m, global step [1;36m2075[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2079: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:18:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2079[0m, global step [1;36m2080[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2084: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:20:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2084[0m, global step [1;36m2085[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2089: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:23:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2089[0m, global step [1;36m2090[0m: [32m'val_loss'[0m reached [1;36m1.82835[0m [1m([0mbest [1;36m1.82835[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2089[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2094: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:25:39][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2094[0m, global step [1;36m2095[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2099: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:28:05][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2099[0m, global step [1;36m2100[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2104: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:30:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2104[0m, global step [1;36m2105[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2109: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:32:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2109[0m, global step [1;36m2110[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2114: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:35:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2114[0m, global step [1;36m2115[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2119: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:37:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2119[0m, global step [1;36m2120[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2124: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:40:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2124[0m, global step [1;36m2125[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2129: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:42:38][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2129[0m, global step [1;36m2130[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2134: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[15:45:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2134[0m, global step [1;36m2135[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2139: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:47:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2139[0m, global step [1;36m2140[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2144: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[15:49:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2144[0m, global step [1;36m2145[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2149: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:52:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2149[0m, global step [1;36m2150[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2154: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[15:54:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2154[0m, global step [1;36m2155[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2159: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[15:57:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2159[0m, global step [1;36m2160[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2164: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:59:44][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2164[0m, global step [1;36m2165[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2169: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[16:02:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2169[0m, global step [1;36m2170[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2174: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.188, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:04:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2174[0m, global step [1;36m2175[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2179: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.181,[2;36m[16:07:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2179[0m, global step [1;36m2180[0m: [32m'val_loss'[0m reached [1;36m1.82835[0m [1m([0mbest [1;36m1.82835[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2179[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8284.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2184: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.185,[2;36m[16:09:30][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2184[0m, global step [1;36m2185[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2189: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:11:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2189[0m, global step [1;36m2190[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2194: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:14:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2194[0m, global step [1;36m2195[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2199: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:16:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2199[0m, global step [1;36m2200[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2204: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:19:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2204[0m, global step [1;36m2205[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2209: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[16:21:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2209[0m, global step [1;36m2210[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2214: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[16:24:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2214[0m, global step [1;36m2215[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2219: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[16:26:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2219[0m, global step [1;36m2220[0m: [32m'val_loss'[0m reached [1;36m1.82835[0m [1m([0mbest [1;36m1.82835[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2219[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2224: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:29:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2224[0m, global step [1;36m2225[0m: [32m'val_loss'[0m reached [1;36m1.82834[0m [1m([0mbest [1;36m1.82834[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2224[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2229: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:31:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2229[0m, global step [1;36m2230[0m: [32m'val_loss'[0m reached [1;36m1.82834[0m [1m([0mbest [1;36m1.82834[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2229[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2234: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:34:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2234[0m, global step [1;36m2235[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2239: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:36:30][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2239[0m, global step [1;36m2240[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2244: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:38:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2244[0m, global step [1;36m2245[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2249: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:41:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2249[0m, global step [1;36m2250[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2254: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:43:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2254[0m, global step [1;36m2255[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2259: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.185,[2;36m[16:46:16][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2259[0m, global step [1;36m2260[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2264: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:48:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2264[0m, global step [1;36m2265[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2269: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:51:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2269[0m, global step [1;36m2270[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2274: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:53:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2274[0m, global step [1;36m2275[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2279: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:56:00][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2279[0m, global step [1;36m2280[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2284: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:58:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2284[0m, global step [1;36m2285[0m: [32m'val_loss'[0m reached [1;36m1.82834[0m [1m([0mbest [1;36m1.82834[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2284[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2289: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:00:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2289[0m, global step [1;36m2290[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2294: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[17:03:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2294[0m, global step [1;36m2295[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2299: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:05:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2299[0m, global step [1;36m2300[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2304: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:08:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2304[0m, global step [1;36m2305[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2309: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:10:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2309[0m, global step [1;36m2310[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2314: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:13:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2314[0m, global step [1;36m2315[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2319: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:15:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2319[0m, global step [1;36m2320[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2324: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:17:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2324[0m, global step [1;36m2325[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2329: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:20:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2329[0m, global step [1;36m2330[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2334: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:22:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2334[0m, global step [1;36m2335[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2339: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:25:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2339[0m, global step [1;36m2340[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2344: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:27:40][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2344[0m, global step [1;36m2345[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2349: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:30:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2349[0m, global step [1;36m2350[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2354: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[17:32:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2354[0m, global step [1;36m2355[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2359: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.186,[2;36m[17:34:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2359[0m, global step [1;36m2360[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2364: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:37:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2364[0m, global step [1;36m2365[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2369: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:39:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2369[0m, global step [1;36m2370[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2374: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:42:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2374[0m, global step [1;36m2375[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2379: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:44:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2379[0m, global step [1;36m2380[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2384: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:47:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2384[0m, global step [1;36m2385[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2389: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:49:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2389[0m, global step [1;36m2390[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2394: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[17:51:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2394[0m, global step [1;36m2395[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2399: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:54:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2399[0m, global step [1;36m2400[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2404: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:56:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2404[0m, global step [1;36m2405[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2409: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:59:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2409[0m, global step [1;36m2410[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2414: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:01:44][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2414[0m, global step [1;36m2415[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2419: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:04:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2419[0m, global step [1;36m2420[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2424: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:06:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2424[0m, global step [1;36m2425[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2429: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:09:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2429[0m, global step [1;36m2430[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2434: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:11:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2434[0m, global step [1;36m2435[0m: [32m'val_loss'[0m reached [1;36m1.82833[0m [1m([0mbest [1;36m1.82833[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2434[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2439: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:13:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2439[0m, global step [1;36m2440[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2444: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:16:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2444[0m, global step [1;36m2445[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2449: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:18:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2449[0m, global step [1;36m2450[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2454: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:21:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2454[0m, global step [1;36m2455[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2459: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:23:39][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2459[0m, global step [1;36m2460[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2464: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:26:05][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2464[0m, global step [1;36m2465[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2469: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:28:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2469[0m, global step [1;36m2470[0m: [32m'val_loss'[0m reached [1;36m1.82833[0m [1m([0mbest [1;36m1.82833[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2469[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2474: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:30:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2474[0m, global step [1;36m2475[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2479: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:33:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2479[0m, global step [1;36m2480[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2484: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[18:35:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2484[0m, global step [1;36m2485[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2489: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:38:16][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2489[0m, global step [1;36m2490[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2494: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:40:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2494[0m, global step [1;36m2495[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2499: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.185,[2;36m[18:43:07][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2499[0m, global step [1;36m2500[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2504: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:45:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2504[0m, global step [1;36m2505[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2509: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:48:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2509[0m, global step [1;36m2510[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2514: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:50:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2514[0m, global step [1;36m2515[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2519: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:52:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2519[0m, global step [1;36m2520[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2524: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:55:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2524[0m, global step [1;36m2525[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2529: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:57:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2529[0m, global step [1;36m2530[0m: [32m'val_loss'[0m reached [1;36m1.82833[0m [1m([0mbest [1;36m1.82833[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2529[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2534: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:00:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2534[0m, global step [1;36m2535[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2539: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:02:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2539[0m, global step [1;36m2540[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2544: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:05:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2544[0m, global step [1;36m2545[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2549: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[19:07:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2549[0m, global step [1;36m2550[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2554: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:09:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2554[0m, global step [1;36m2555[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2559: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:12:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2559[0m, global step [1;36m2560[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2564: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:14:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2564[0m, global step [1;36m2565[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2569: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:17:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2569[0m, global step [1;36m2570[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2574: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:19:40][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2574[0m, global step [1;36m2575[0m: [32m'val_loss'[0m reached [1;36m1.82833[0m [1m([0mbest [1;36m1.82833[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2574[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2579: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:22:07][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2579[0m, global step [1;36m2580[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2584: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:24:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2584[0m, global step [1;36m2585[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2589: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:27:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2589[0m, global step [1;36m2590[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2594: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:29:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2594[0m, global step [1;36m2595[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2599: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:31:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2599[0m, global step [1;36m2600[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2604: 100%|█| 1/1 [01:25<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:35:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2604[0m, global step [1;36m2605[0m: [32m'val_loss'[0m reached [1;36m1.82832[0m [1m([0mbest [1;36m1.82832[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2604[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2609: 100%|█| 1/1 [02:11<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:46:05][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2609[0m, global step [1;36m2610[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2614: 100%|█| 1/1 [02:13<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:55:44][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2614[0m, global step [1;36m2615[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2619: 100%|█| 1/1 [01:21<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:05:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2619[0m, global step [1;36m2620[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2624: 100%|█| 1/1 [02:16<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:13:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2624[0m, global step [1;36m2625[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2629: 100%|█| 1/1 [01:51<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:22:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2629[0m, global step [1;36m2630[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2634: 100%|█| 1/1 [01:46<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:34:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2634[0m, global step [1;36m2635[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2639: 100%|█| 1/1 [01:33<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:45:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2639[0m, global step [1;36m2640[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2644: 100%|█| 1/1 [02:40<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:54:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2644[0m, global step [1;36m2645[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2649: 100%|█| 1/1 [02:24<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:05:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2649[0m, global step [1;36m2650[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2654: 100%|█| 1/1 [01:51<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:15:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2654[0m, global step [1;36m2655[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2659: 100%|█| 1/1 [02:00<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:26:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2659[0m, global step [1;36m2660[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2664: 100%|█| 1/1 [01:59<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:31:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2664[0m, global step [1;36m2665[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2669: 100%|█| 1/1 [02:42<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:43:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2669[0m, global step [1;36m2670[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2674: 100%|█| 1/1 [02:53<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:56:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2674[0m, global step [1;36m2675[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2679: 100%|█| 1/1 [02:48<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:07:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2679[0m, global step [1;36m2680[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2684: 100%|█| 1/1 [01:00<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:14:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2684[0m, global step [1;36m2685[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2689: 100%|█| 1/1 [02:31<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:25:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2689[0m, global step [1;36m2690[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2694: 100%|█| 1/1 [02:43<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:36:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2694[0m, global step [1;36m2695[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2699: 100%|█| 1/1 [02:09<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:46:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2699[0m, global step [1;36m2700[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2704: 100%|█| 1/1 [02:27<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:55:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2704[0m, global step [1;36m2705[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2709: 100%|█| 1/1 [02:14<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:06:40][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2709[0m, global step [1;36m2710[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2714: 100%|█| 1/1 [01:47<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:14:40][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2714[0m, global step [1;36m2715[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2719: 100%|█| 1/1 [01:20<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:22:30][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2719[0m, global step [1;36m2720[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2724: 100%|█| 1/1 [01:47<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:31:13][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2724[0m, global step [1;36m2725[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2729: 100%|█| 1/1 [01:46<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:36:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2729[0m, global step [1;36m2730[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2734: 100%|█| 1/1 [01:34<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:44:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2734[0m, global step [1;36m2735[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2739: 100%|█| 1/1 [02:30<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:53:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2739[0m, global step [1;36m2740[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2744: 100%|█| 1/1 [02:19<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[00:04:30][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2744[0m, global step [1;36m2745[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2749: 100%|█| 1/1 [01:48<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[00:14:38][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2749[0m, global step [1;36m2750[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2754: 100%|█| 1/1 [02:41<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[00:24:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2754[0m, global step [1;36m2755[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2759: 100%|█| 1/1 [02:03<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[00:34:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2759[0m, global step [1;36m2760[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2764: 100%|█| 1/1 [01:45<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[00:44:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2764[0m, global step [1;36m2765[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2769: 100%|█| 1/1 [02:43<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[00:54:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2769[0m, global step [1;36m2770[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2774: 100%|█| 1/1 [01:53<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:03:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2774[0m, global step [1;36m2775[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2779: 100%|█| 1/1 [02:13<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:13:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2779[0m, global step [1;36m2780[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2784: 100%|█| 1/1 [02:48<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:24:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2784[0m, global step [1;36m2785[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2789: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:33:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2789[0m, global step [1;36m2790[0m: [32m'val_loss'[0m reached [1;36m1.82833[0m [1m([0mbest [1;36m1.82832[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2789[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2794: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:35:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2794[0m, global step [1;36m2795[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2799: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:37:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2799[0m, global step [1;36m2800[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2804: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:40:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2804[0m, global step [1;36m2805[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2809: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:42:38][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2809[0m, global step [1;36m2810[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2814: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:45:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2814[0m, global step [1;36m2815[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2819: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:48:16][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2819[0m, global step [1;36m2820[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2824: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:51:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2824[0m, global step [1;36m2825[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2829: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:54:13][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2829[0m, global step [1;36m2830[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2834: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:56:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2834[0m, global step [1;36m2835[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2839: 100%|█| 1/1 [00:52<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:59:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2839[0m, global step [1;36m2840[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2844: 100%|█| 1/1 [00:47<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:03:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2844[0m, global step [1;36m2845[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2849: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:06:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2849[0m, global step [1;36m2850[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2854: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:09:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2854[0m, global step [1;36m2855[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2859: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:12:16][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2859[0m, global step [1;36m2860[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2864: 100%|█| 1/1 [02:41<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:18:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2864[0m, global step [1;36m2865[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2869: 100%|█| 1/1 [02:38<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:31:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2869[0m, global step [1;36m2870[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2874: 100%|█| 1/1 [01:33<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:37:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2874[0m, global step [1;36m2875[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2879: 100%|█| 1/1 [01:57<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:44:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2879[0m, global step [1;36m2880[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2884: 100%|█| 1/1 [01:55<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:52:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2884[0m, global step [1;36m2885[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2889: 100%|█| 1/1 [01:18<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[02:59:07][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2889[0m, global step [1;36m2890[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2894: 100%|█| 1/1 [01:51<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:05:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2894[0m, global step [1;36m2895[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2899: 100%|█| 1/1 [00:49<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:11:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2899[0m, global step [1;36m2900[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2904: 100%|█| 1/1 [02:52<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:18:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2904[0m, global step [1;36m2905[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2909: 100%|█| 1/1 [01:51<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:26:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2909[0m, global step [1;36m2910[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2914: 100%|█| 1/1 [01:54<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:34:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2914[0m, global step [1;36m2915[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2919: 100%|█| 1/1 [01:31<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:41:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2919[0m, global step [1;36m2920[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2924: 100%|█| 1/1 [01:08<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:47:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2924[0m, global step [1;36m2925[0m: [32m'val_loss'[0m reached [1;36m1.82832[0m [1m([0mbest [1;36m1.82832[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2924[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2929: 100%|█| 1/1 [02:05<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:55:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2929[0m, global step [1;36m2930[0m: [32m'val_loss'[0m reached [1;36m1.82832[0m [1m([0mbest [1;36m1.82832[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2929[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2934: 100%|█| 1/1 [02:02<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:04:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2934[0m, global step [1;36m2935[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2939: 100%|█| 1/1 [01:40<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:12:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2939[0m, global step [1;36m2940[0m: [32m'val_loss'[0m reached [1;36m1.82832[0m [1m([0mbest [1;36m1.82832[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m2939[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 2944: 100%|█| 1/1 [01:28<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:19:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2944[0m, global step [1;36m2945[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2949: 100%|█| 1/1 [01:19<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:26:02][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2949[0m, global step [1;36m2950[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2954: 100%|█| 1/1 [02:02<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:33:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2954[0m, global step [1;36m2955[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2959: 100%|█| 1/1 [01:56<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:42:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2959[0m, global step [1;36m2960[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2964: 100%|█| 1/1 [01:45<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:50:07][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2964[0m, global step [1;36m2965[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2969: 100%|█| 1/1 [01:11<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:54:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2969[0m, global step [1;36m2970[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2974: 100%|█| 1/1 [00:45<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:00:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2974[0m, global step [1;36m2975[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2979: 100%|█| 1/1 [01:40<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:05:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2979[0m, global step [1;36m2980[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2984: 100%|█| 1/1 [01:35<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:12:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2984[0m, global step [1;36m2985[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2989: 100%|█| 1/1 [01:20<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:18:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2989[0m, global step [1;36m2990[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2994: 100%|█| 1/1 [00:57<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:23:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2994[0m, global step [1;36m2995[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 2999: 100%|█| 1/1 [00:56<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:28:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m2999[0m, global step [1;36m3000[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3004: 100%|█| 1/1 [01:20<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:33:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3004[0m, global step [1;36m3005[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3009: 100%|█| 1/1 [01:18<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:39:44][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3009[0m, global step [1;36m3010[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3014: 100%|█| 1/1 [01:39<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:46:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3014[0m, global step [1;36m3015[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3019: 100%|█| 1/1 [01:00<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:51:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3019[0m, global step [1;36m3020[0m: [32m'val_loss'[0m reached [1;36m1.82832[0m [1m([0mbest [1;36m1.82832[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3019[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3024: 100%|█| 1/1 [01:20<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:56:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3024[0m, global step [1;36m3025[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3029: 100%|█| 1/1 [01:01<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:01:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3029[0m, global step [1;36m3030[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3034: 100%|█| 1/1 [01:28<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:08:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3034[0m, global step [1;36m3035[0m: [32m'val_loss'[0m reached [1;36m1.82832[0m [1m([0mbest [1;36m1.82832[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3034[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3039: 100%|█| 1/1 [01:26<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:15:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3039[0m, global step [1;36m3040[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3044: 100%|█| 1/1 [01:15<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:21:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3044[0m, global step [1;36m3045[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3049: 100%|█| 1/1 [01:23<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:26:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3049[0m, global step [1;36m3050[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3054: 100%|█| 1/1 [01:04<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:31:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3054[0m, global step [1;36m3055[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3059: 100%|█| 1/1 [01:32<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:38:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3059[0m, global step [1;36m3060[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3064: 100%|█| 1/1 [01:14<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:45:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3064[0m, global step [1;36m3065[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3069: 100%|█| 1/1 [01:24<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:51:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3069[0m, global step [1;36m3070[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3074: 100%|█| 1/1 [01:19<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:57:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3074[0m, global step [1;36m3075[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3079: 100%|█| 1/1 [00:58<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:01:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3079[0m, global step [1;36m3080[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3084: 100%|█| 1/1 [01:19<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[07:06:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3084[0m, global step [1;36m3085[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3089: 100%|█| 1/1 [01:30<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:13:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3089[0m, global step [1;36m3090[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3094: 100%|█| 1/1 [00:52<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:17:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3094[0m, global step [1;36m3095[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3099: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:21:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3099[0m, global step [1;36m3100[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3104: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:24:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3104[0m, global step [1;36m3105[0m: [32m'val_loss'[0m reached [1;36m1.82832[0m [1m([0mbest [1;36m1.82832[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3104[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3109: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:27:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3109[0m, global step [1;36m3110[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3114: 100%|█| 1/1 [01:05<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:30:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3114[0m, global step [1;36m3115[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3119: 100%|█| 1/1 [01:09<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:35:40][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3119[0m, global step [1;36m3120[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3124: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:39:02][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3124[0m, global step [1;36m3125[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3124[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3129: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:41:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3129[0m, global step [1;36m3130[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3134: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:44:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3134[0m, global step [1;36m3135[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3139: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:47:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3139[0m, global step [1;36m3140[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3144: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:49:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3144[0m, global step [1;36m3145[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3149: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:52:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3149[0m, global step [1;36m3150[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3149[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3154: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:54:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3154[0m, global step [1;36m3155[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3159: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:57:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3159[0m, global step [1;36m3160[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3164: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:59:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3164[0m, global step [1;36m3165[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3169: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:01:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3169[0m, global step [1;36m3170[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3174: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:04:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3174[0m, global step [1;36m3175[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3179: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:06:40][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3179[0m, global step [1;36m3180[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3184: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:09:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3184[0m, global step [1;36m3185[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3189: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:11:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3189[0m, global step [1;36m3190[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3189[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3194: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:13:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3194[0m, global step [1;36m3195[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3199: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:16:13][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3199[0m, global step [1;36m3200[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3204: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:18:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3204[0m, global step [1;36m3205[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3209: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:20:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3209[0m, global step [1;36m3210[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3209[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3214: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:23:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3214[0m, global step [1;36m3215[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3214[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3219: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:25:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3219[0m, global step [1;36m3220[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3224: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:28:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3224[0m, global step [1;36m3225[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3229: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:30:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3229[0m, global step [1;36m3230[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3234: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:32:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3234[0m, global step [1;36m3235[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3239: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:35:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3239[0m, global step [1;36m3240[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3244: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[08:37:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3244[0m, global step [1;36m3245[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3249: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:40:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3249[0m, global step [1;36m3250[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3254: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:42:28][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3254[0m, global step [1;36m3255[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3259: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:44:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3259[0m, global step [1;36m3260[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3264: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:47:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3264[0m, global step [1;36m3265[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3269: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:49:38][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3269[0m, global step [1;36m3270[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3274: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[08:52:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3274[0m, global step [1;36m3275[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3279: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:54:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3279[0m, global step [1;36m3280[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3284: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.182, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:56:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3284[0m, global step [1;36m3285[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3289: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:59:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3289[0m, global step [1;36m3290[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3294: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:01:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3294[0m, global step [1;36m3295[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3299: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:03:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3299[0m, global step [1;36m3300[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3304: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:06:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3304[0m, global step [1;36m3305[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3304[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3309: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:08:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3309[0m, global step [1;36m3310[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3309[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3314: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:11:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3314[0m, global step [1;36m3315[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3319: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:13:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3319[0m, global step [1;36m3320[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3319[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3324: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:15:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3324[0m, global step [1;36m3325[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3329: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:18:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3329[0m, global step [1;36m3330[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3334: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:20:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3334[0m, global step [1;36m3335[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3339: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:23:02][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3339[0m, global step [1;36m3340[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3344: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:25:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3344[0m, global step [1;36m3345[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3349: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:27:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3349[0m, global step [1;36m3350[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3354: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:30:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3354[0m, global step [1;36m3355[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3359: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:32:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3359[0m, global step [1;36m3360[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3364: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:34:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3364[0m, global step [1;36m3365[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3369: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:37:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3369[0m, global step [1;36m3370[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3374: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[09:39:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3374[0m, global step [1;36m3375[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3379: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:42:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3379[0m, global step [1;36m3380[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3384: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[09:44:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3384[0m, global step [1;36m3385[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3389: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.180, train_loss_epoch=1.830, train_acc_epoch=0.178,[2;36m[09:46:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3389[0m, global step [1;36m3390[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3394: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:49:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3394[0m, global step [1;36m3395[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3399: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:51:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3399[0m, global step [1;36m3400[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3404: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:54:05][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3404[0m, global step [1;36m3405[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3409: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:56:28][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3409[0m, global step [1;36m3410[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3414: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.179, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:58:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3414[0m, global step [1;36m3415[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3419: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:01:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3419[0m, global step [1;36m3420[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3424: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:03:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3424[0m, global step [1;36m3425[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3429: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:06:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3429[0m, global step [1;36m3430[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3434: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:08:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3434[0m, global step [1;36m3435[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3439: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:10:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3439[0m, global step [1;36m3440[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3444: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[10:13:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3444[0m, global step [1;36m3445[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3449: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:15:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3449[0m, global step [1;36m3450[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3454: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:17:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3454[0m, global step [1;36m3455[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3459: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:20:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3459[0m, global step [1;36m3460[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3464: 100%|█| 1/1 [00:31<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:22:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3464[0m, global step [1;36m3465[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3469: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:25:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3469[0m, global step [1;36m3470[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3474: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:27:28][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3474[0m, global step [1;36m3475[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3479: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:29:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3479[0m, global step [1;36m3480[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3484: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:32:38][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3484[0m, global step [1;36m3485[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3489: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:35:30][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3489[0m, global step [1;36m3490[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3494: 100%|█| 1/1 [00:52<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:39:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3494[0m, global step [1;36m3495[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3499: 100%|█| 1/1 [01:03<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:43:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3499[0m, global step [1;36m3500[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3499[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3504: 100%|█| 1/1 [00:56<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:47:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3504[0m, global step [1;36m3505[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3509: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:51:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3509[0m, global step [1;36m3510[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3514: 100%|█| 1/1 [00:48<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:54:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3514[0m, global step [1;36m3515[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3514[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3519: 100%|█| 1/1 [00:51<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:58:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3519[0m, global step [1;36m3520[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3524: 100%|█| 1/1 [00:56<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:02:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3524[0m, global step [1;36m3525[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3524[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3529: 100%|█| 1/1 [00:47<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:05:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3529[0m, global step [1;36m3530[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3534: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:08:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3534[0m, global step [1;36m3535[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3534[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3539: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:11:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3539[0m, global step [1;36m3540[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3544: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:14:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3544[0m, global step [1;36m3545[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3549: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:17:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3549[0m, global step [1;36m3550[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3549[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3554: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:20:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3554[0m, global step [1;36m3555[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3554[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3559: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:23:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3559[0m, global step [1;36m3560[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3564: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:25:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3564[0m, global step [1;36m3565[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3569: 100%|█| 1/1 [00:53<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:28:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3569[0m, global step [1;36m3570[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3569[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3574: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:31:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3574[0m, global step [1;36m3575[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3579: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:34:38][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3579[0m, global step [1;36m3580[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3584: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:37:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3584[0m, global step [1;36m3585[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3589: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:40:40][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3589[0m, global step [1;36m3590[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3594: 100%|█| 1/1 [00:46<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:43:30][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3594[0m, global step [1;36m3595[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3599: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[11:46:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3599[0m, global step [1;36m3600[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3604: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:48:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3604[0m, global step [1;36m3605[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3609: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:51:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3609[0m, global step [1;36m3610[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3614: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.189, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[11:53:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3614[0m, global step [1;36m3615[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3619: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[11:56:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3619[0m, global step [1;36m3620[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3624: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:00:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3624[0m, global step [1;36m3625[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3629: 100%|█| 1/1 [00:45<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:03:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3629[0m, global step [1;36m3630[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3634: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:06:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3634[0m, global step [1;36m3635[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3639: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:10:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3639[0m, global step [1;36m3640[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3644: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.185, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:13:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3644[0m, global step [1;36m3645[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3649: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.188, train_loss_epoch=1.830, train_acc_epoch=0.185,[2;36m[12:15:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3649[0m, global step [1;36m3650[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3654: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:19:00][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3654[0m, global step [1;36m3655[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3659: 100%|█| 1/1 [00:49<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:21:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3659[0m, global step [1;36m3660[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3664: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:24:39][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3664[0m, global step [1;36m3665[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3669: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[12:27:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3669[0m, global step [1;36m3670[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3674: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:30:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3674[0m, global step [1;36m3675[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3679: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:33:28][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3679[0m, global step [1;36m3680[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3684: 100%|█| 1/1 [00:46<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:36:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3684[0m, global step [1;36m3685[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3689: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:38:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3689[0m, global step [1;36m3690[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3694: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:41:28][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3694[0m, global step [1;36m3695[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3699: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:43:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3699[0m, global step [1;36m3700[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3704: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:46:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3704[0m, global step [1;36m3705[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3709: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:48:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3709[0m, global step [1;36m3710[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3714: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:51:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3714[0m, global step [1;36m3715[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3719: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:53:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3719[0m, global step [1;36m3720[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3719[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3724: 100%|█| 1/1 [00:58<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:57:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3724[0m, global step [1;36m3725[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3724[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3729: 100%|█| 1/1 [00:57<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:00:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3729[0m, global step [1;36m3730[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3734: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:04:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3734[0m, global step [1;36m3735[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3739: 100%|█| 1/1 [01:33<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:08:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3739[0m, global step [1;36m3740[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3739[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3744: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:12:16][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3744[0m, global step [1;36m3745[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3749: 100%|█| 1/1 [01:20<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:16:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3749[0m, global step [1;36m3750[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3754: 100%|█| 1/1 [00:48<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:20:02][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3754[0m, global step [1;36m3755[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3759: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[13:23:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3759[0m, global step [1;36m3760[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3764: 100%|█| 1/1 [00:45<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:28:05][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3764[0m, global step [1;36m3765[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3769: 100%|█| 1/1 [00:46<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:31:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3769[0m, global step [1;36m3770[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3774: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:36:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3774[0m, global step [1;36m3775[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3779: 100%|█| 1/1 [00:57<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:40:07][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3779[0m, global step [1;36m3780[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3779[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3784: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:44:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3784[0m, global step [1;36m3785[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3789: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:47:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3789[0m, global step [1;36m3790[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3794: 100%|█| 1/1 [01:10<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:52:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3794[0m, global step [1;36m3795[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3799: 100%|█| 1/1 [00:52<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:56:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3799[0m, global step [1;36m3800[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3804: 100%|█| 1/1 [01:00<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:02:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3804[0m, global step [1;36m3805[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3809: 100%|█| 1/1 [01:06<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:07:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3809[0m, global step [1;36m3810[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3814: 100%|█| 1/1 [01:48<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:13:00][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3814[0m, global step [1;36m3815[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3819: 100%|█| 1/1 [01:17<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:18:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3819[0m, global step [1;36m3820[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3824: 100%|█| 1/1 [01:00<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:22:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3824[0m, global step [1;36m3825[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3829: 100%|█| 1/1 [01:24<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:28:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3829[0m, global step [1;36m3830[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3834: 100%|█| 1/1 [01:23<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:33:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3834[0m, global step [1;36m3835[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3839: 100%|█| 1/1 [01:32<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.195, train_loss_epoch=1.830, train_acc_epoch=0.182,[2;36m[14:40:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3839[0m, global step [1;36m3840[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3844: 100%|█| 1/1 [01:34<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:45:40][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3844[0m, global step [1;36m3845[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3849: 100%|█| 1/1 [01:35<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:50:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3849[0m, global step [1;36m3850[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3854: 100%|█| 1/1 [01:26<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.178,[2;36m[14:57:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3854[0m, global step [1;36m3855[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3859: 100%|█| 1/1 [01:29<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:02:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3859[0m, global step [1;36m3860[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3864: 100%|█| 1/1 [01:23<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:09:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3864[0m, global step [1;36m3865[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3869: 100%|█| 1/1 [01:40<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:14:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3869[0m, global step [1;36m3870[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3874: 100%|█| 1/1 [01:47<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:20:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3874[0m, global step [1;36m3875[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3879: 100%|█| 1/1 [01:30<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:27:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3879[0m, global step [1;36m3880[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3884: 100%|█| 1/1 [01:15<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.181, train_loss_epoch=1.830, train_acc_epoch=0.182,[2;36m[15:32:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3884[0m, global step [1;36m3885[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3889: 100%|█| 1/1 [01:32<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.193, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[15:38:05][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3889[0m, global step [1;36m3890[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3894: 100%|█| 1/1 [00:50<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:42:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3894[0m, global step [1;36m3895[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3899: 100%|█| 1/1 [00:55<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:46:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3899[0m, global step [1;36m3900[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3904: 100%|█| 1/1 [01:02<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:52:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3904[0m, global step [1;36m3905[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3909: 100%|█| 1/1 [00:55<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:56:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3909[0m, global step [1;36m3910[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3914: 100%|█| 1/1 [00:47<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:00:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3914[0m, global step [1;36m3915[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3919: 100%|█| 1/1 [00:50<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:04:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3919[0m, global step [1;36m3920[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3924: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:08:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3924[0m, global step [1;36m3925[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3929: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:11:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3929[0m, global step [1;36m3930[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3934: 100%|█| 1/1 [00:59<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:16:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3934[0m, global step [1;36m3935[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3939: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:19:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3939[0m, global step [1;36m3940[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3944: 100%|█| 1/1 [01:02<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:23:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3944[0m, global step [1;36m3945[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3949: 100%|█| 1/1 [00:56<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:27:38][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3949[0m, global step [1;36m3950[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3954: 100%|█| 1/1 [00:46<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:31:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3954[0m, global step [1;36m3955[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3959: 100%|█| 1/1 [01:06<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:35:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3959[0m, global step [1;36m3960[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3964: 100%|█| 1/1 [00:52<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:39:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3964[0m, global step [1;36m3965[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3969: 100%|█| 1/1 [01:06<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:43:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3969[0m, global step [1;36m3970[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3969[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3974: 100%|█| 1/1 [01:09<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:47:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3974[0m, global step [1;36m3975[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3979: 100%|█| 1/1 [01:00<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:51:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3979[0m, global step [1;36m3980[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3984: 100%|█| 1/1 [01:07<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:55:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3984[0m, global step [1;36m3985[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3989: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:59:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3989[0m, global step [1;36m3990[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m3989[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 3994: 100%|█| 1/1 [01:00<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:02:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3994[0m, global step [1;36m3995[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 3999: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:06:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m3999[0m, global step [1;36m4000[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4004: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:09:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4004[0m, global step [1;36m4005[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m4004[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 4009: 100%|█| 1/1 [00:50<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:13:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4009[0m, global step [1;36m4010[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4014: 100%|█| 1/1 [00:49<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:17:02][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4014[0m, global step [1;36m4015[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4019: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:19:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4019[0m, global step [1;36m4020[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m4019[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 4024: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:22:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4024[0m, global step [1;36m4025[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4029: 100%|█| 1/1 [01:05<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:25:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4029[0m, global step [1;36m4030[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4034: 100%|█| 1/1 [00:50<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:30:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4034[0m, global step [1;36m4035[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4039: 100%|█| 1/1 [01:47<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:36:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4039[0m, global step [1;36m4040[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4044: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:38:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4044[0m, global step [1;36m4045[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4049: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:42:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4049[0m, global step [1;36m4050[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4054: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:45:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4054[0m, global step [1;36m4055[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4059: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:48:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4059[0m, global step [1;36m4060[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4064: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:50:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4064[0m, global step [1;36m4065[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4069: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:53:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4069[0m, global step [1;36m4070[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4074: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:56:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4074[0m, global step [1;36m4075[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m4074[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 4079: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:59:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4079[0m, global step [1;36m4080[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4084: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:02:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4084[0m, global step [1;36m4085[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4089: 100%|█| 1/1 [00:55<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:06:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4089[0m, global step [1;36m4090[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4094: 100%|█| 1/1 [00:56<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:10:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4094[0m, global step [1;36m4095[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m4094[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 4099: 100%|█| 1/1 [00:49<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:13:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4099[0m, global step [1;36m4100[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4104: 100%|█| 1/1 [00:58<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:17:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4104[0m, global step [1;36m4105[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4109: 100%|█| 1/1 [00:56<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:21:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4109[0m, global step [1;36m4110[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4114: 100%|█| 1/1 [00:49<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:25:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4114[0m, global step [1;36m4115[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4119: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:28:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4119[0m, global step [1;36m4120[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4124: 100%|█| 1/1 [00:58<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:32:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4124[0m, global step [1;36m4125[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4129: 100%|█| 1/1 [00:48<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:36:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4129[0m, global step [1;36m4130[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m4129[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 4134: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:40:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4134[0m, global step [1;36m4135[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4139: 100%|█| 1/1 [00:57<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:44:07][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4139[0m, global step [1;36m4140[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4144: 100%|█| 1/1 [00:53<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:48:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4144[0m, global step [1;36m4145[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4149: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:51:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4149[0m, global step [1;36m4150[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4154: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:56:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4154[0m, global step [1;36m4155[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4159: 100%|█| 1/1 [00:52<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:00:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4159[0m, global step [1;36m4160[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4164: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:03:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4164[0m, global step [1;36m4165[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4169: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:07:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4169[0m, global step [1;36m4170[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4174: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:11:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4174[0m, global step [1;36m4175[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4179: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:14:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4179[0m, global step [1;36m4180[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4184: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:17:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4184[0m, global step [1;36m4185[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m4184[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 4189: 100%|█| 1/1 [00:43<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:20:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4189[0m, global step [1;36m4190[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4194: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:23:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4194[0m, global step [1;36m4195[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4199: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:26:05][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4199[0m, global step [1;36m4200[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4204: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:29:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4204[0m, global step [1;36m4205[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4209: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:31:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4209[0m, global step [1;36m4210[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4214: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:34:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4214[0m, global step [1;36m4215[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4219: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:37:40][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4219[0m, global step [1;36m4220[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4224: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:40:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4224[0m, global step [1;36m4225[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4229: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:43:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4229[0m, global step [1;36m4230[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4234: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:46:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4234[0m, global step [1;36m4235[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4239: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:49:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4239[0m, global step [1;36m4240[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4244: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:52:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4244[0m, global step [1;36m4245[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4249: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:55:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4249[0m, global step [1;36m4250[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4254: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:57:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4254[0m, global step [1;36m4255[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4259: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:00:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4259[0m, global step [1;36m4260[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4264: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:03:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4264[0m, global step [1;36m4265[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4269: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:06:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4269[0m, global step [1;36m4270[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4274: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:09:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4274[0m, global step [1;36m4275[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4279: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:12:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4279[0m, global step [1;36m4280[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4284: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:15:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4284[0m, global step [1;36m4285[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4289: 100%|█| 1/1 [00:43<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:18:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4289[0m, global step [1;36m4290[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m4289[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 4294: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:21:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4294[0m, global step [1;36m4295[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4299: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:24:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4299[0m, global step [1;36m4300[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4304: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:27:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4304[0m, global step [1;36m4305[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4309: 100%|█| 1/1 [00:52<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:30:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4309[0m, global step [1;36m4310[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4314: 100%|█| 1/1 [01:06<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:35:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4314[0m, global step [1;36m4315[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4319: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:39:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4319[0m, global step [1;36m4320[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4324: 100%|█| 1/1 [00:53<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:43:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4324[0m, global step [1;36m4325[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4329: 100%|█| 1/1 [00:54<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:48:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4329[0m, global step [1;36m4330[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4334: 100%|█| 1/1 [01:00<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:52:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4334[0m, global step [1;36m4335[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4339: 100%|█| 1/1 [00:43<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:56:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4339[0m, global step [1;36m4340[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4344: 100%|█| 1/1 [00:51<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:01:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4344[0m, global step [1;36m4345[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4349: 100%|█| 1/1 [01:10<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:05:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4349[0m, global step [1;36m4350[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4354: 100%|█| 1/1 [01:12<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:10:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4354[0m, global step [1;36m4355[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4359: 100%|█| 1/1 [00:47<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:14:13][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4359[0m, global step [1;36m4360[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4364: 100%|█| 1/1 [00:58<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:18:38][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4364[0m, global step [1;36m4365[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4369: 100%|█| 1/1 [00:58<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:22:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4369[0m, global step [1;36m4370[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4374: 100%|█| 1/1 [00:45<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:26:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4374[0m, global step [1;36m4375[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4379: 100%|█| 1/1 [00:43<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:29:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4379[0m, global step [1;36m4380[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4384: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:32:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4384[0m, global step [1;36m4385[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4389: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:36:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4389[0m, global step [1;36m4390[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4394: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:38:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4394[0m, global step [1;36m4395[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4399: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:42:00][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4399[0m, global step [1;36m4400[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4404: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:45:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4404[0m, global step [1;36m4405[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4409: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:48:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4409[0m, global step [1;36m4410[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4414: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:51:02][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4414[0m, global step [1;36m4415[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4419: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:54:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4419[0m, global step [1;36m4420[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4424: 100%|█| 1/1 [00:47<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:57:16][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4424[0m, global step [1;36m4425[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4429: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:00:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4429[0m, global step [1;36m4430[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4434: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:03:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4434[0m, global step [1;36m4435[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4439: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:06:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4439[0m, global step [1;36m4440[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4444: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:09:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4444[0m, global step [1;36m4445[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4449: 100%|█| 1/1 [00:46<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:12:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4449[0m, global step [1;36m4450[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4454: 100%|█| 1/1 [00:46<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:15:38][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4454[0m, global step [1;36m4455[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4459: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:18:44][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4459[0m, global step [1;36m4460[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4464: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:21:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4464[0m, global step [1;36m4465[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4469: 100%|█| 1/1 [01:02<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:25:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4469[0m, global step [1;36m4470[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4474: 100%|█| 1/1 [01:15<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:29:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4474[0m, global step [1;36m4475[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4479: 100%|█| 1/1 [01:21<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:34:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4479[0m, global step [1;36m4480[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4484: 100%|█| 1/1 [01:03<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:38:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4484[0m, global step [1;36m4485[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4489: 100%|█| 1/1 [00:43<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:42:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4489[0m, global step [1;36m4490[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4494: 100%|█| 1/1 [00:57<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:46:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4494[0m, global step [1;36m4495[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4499: 100%|█| 1/1 [01:02<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:50:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4499[0m, global step [1;36m4500[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4504: 100%|█| 1/1 [00:59<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:54:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4504[0m, global step [1;36m4505[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4509: 100%|█| 1/1 [00:52<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[22:57:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4509[0m, global step [1;36m4510[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4514: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:01:05][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4514[0m, global step [1;36m4515[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4519: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:03:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4519[0m, global step [1;36m4520[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4524: 100%|█| 1/1 [00:45<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:06:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4524[0m, global step [1;36m4525[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4529: 100%|█| 1/1 [00:45<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:09:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4529[0m, global step [1;36m4530[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m4529[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 4534: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:12:44][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4534[0m, global step [1;36m4535[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4539: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:15:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4539[0m, global step [1;36m4540[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4544: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:18:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4544[0m, global step [1;36m4545[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4549: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:21:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4549[0m, global step [1;36m4550[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4554: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:24:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4554[0m, global step [1;36m4555[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4559: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:27:30][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4559[0m, global step [1;36m4560[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4564: 100%|█| 1/1 [02:23<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:36:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4564[0m, global step [1;36m4565[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m4564[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 4569: 100%|█| 1/1 [02:10<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:47:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4569[0m, global step [1;36m4570[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4574: 100%|█| 1/1 [02:35<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[23:55:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4574[0m, global step [1;36m4575[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4579: 100%|█| 1/1 [01:41<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[00:03:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4579[0m, global step [1;36m4580[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4584: 100%|█| 1/1 [02:31<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[00:13:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4584[0m, global step [1;36m4585[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4589: 100%|█| 1/1 [01:20<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[00:22:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4589[0m, global step [1;36m4590[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m4589[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 4594: 100%|█| 1/1 [01:07<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[00:31:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4594[0m, global step [1;36m4595[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4599: 100%|█| 1/1 [02:15<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[00:40:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4599[0m, global step [1;36m4600[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4604: 100%|█| 1/1 [02:55<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[00:52:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4604[0m, global step [1;36m4605[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4609: 100%|█| 1/1 [02:29<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:00:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4609[0m, global step [1;36m4610[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4614: 100%|█| 1/1 [02:09<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:09:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4614[0m, global step [1;36m4615[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4619: 100%|█| 1/1 [02:58<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:20:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4619[0m, global step [1;36m4620[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4624: 100%|█| 1/1 [01:40<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:30:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4624[0m, global step [1;36m4625[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4629: 100%|█| 1/1 [02:18<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:38:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4629[0m, global step [1;36m4630[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4634: 100%|█| 1/1 [02:27<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:47:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4634[0m, global step [1;36m4635[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4639: 100%|█| 1/1 [02:42<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[01:57:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4639[0m, global step [1;36m4640[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4644: 100%|█| 1/1 [01:19<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:07:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4644[0m, global step [1;36m4645[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4649: 100%|█| 1/1 [01:39<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:14:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4649[0m, global step [1;36m4650[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4654: 100%|█| 1/1 [01:29<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:21:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4654[0m, global step [1;36m4655[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4659: 100%|█| 1/1 [00:47<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:25:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4659[0m, global step [1;36m4660[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4664: 100%|█| 1/1 [01:23<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:30:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4664[0m, global step [1;36m4665[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4669: 100%|█| 1/1 [00:50<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:35:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4669[0m, global step [1;36m4670[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4674: 100%|█| 1/1 [00:52<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:39:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4674[0m, global step [1;36m4675[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4679: 100%|█| 1/1 [00:57<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:44:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4679[0m, global step [1;36m4680[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4684: 100%|█| 1/1 [00:55<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:48:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4684[0m, global step [1;36m4685[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4689: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:52:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4689[0m, global step [1;36m4690[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4694: 100%|█| 1/1 [01:32<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[02:59:00][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4694[0m, global step [1;36m4695[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4699: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:02:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4699[0m, global step [1;36m4700[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4704: 100%|█| 1/1 [01:13<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:06:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4704[0m, global step [1;36m4705[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4709: 100%|█| 1/1 [01:26<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:12:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4709[0m, global step [1;36m4710[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4714: 100%|█| 1/1 [00:54<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:16:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4714[0m, global step [1;36m4715[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4719: 100%|█| 1/1 [01:31<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:21:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4719[0m, global step [1;36m4720[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4724: 100%|█| 1/1 [00:47<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:26:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4724[0m, global step [1;36m4725[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4729: 100%|█| 1/1 [00:48<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:30:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4729[0m, global step [1;36m4730[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4734: 100%|█| 1/1 [01:25<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:35:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4734[0m, global step [1;36m4735[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4739: 100%|█| 1/1 [00:50<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:40:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4739[0m, global step [1;36m4740[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4744: 100%|█| 1/1 [00:57<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:44:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4744[0m, global step [1;36m4745[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4749: 100%|█| 1/1 [01:40<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:50:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4749[0m, global step [1;36m4750[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4754: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:55:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4754[0m, global step [1;36m4755[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4759: 100%|█| 1/1 [00:50<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[03:58:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4759[0m, global step [1;36m4760[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4764: 100%|█| 1/1 [01:41<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:04:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4764[0m, global step [1;36m4765[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4769: 100%|█| 1/1 [00:48<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:09:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4769[0m, global step [1;36m4770[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4774: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:13:02][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4774[0m, global step [1;36m4775[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4779: 100%|█| 1/1 [01:27<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:19:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4779[0m, global step [1;36m4780[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4784: 100%|█| 1/1 [00:51<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:23:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4784[0m, global step [1;36m4785[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4789: 100%|█| 1/1 [00:49<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:26:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4789[0m, global step [1;36m4790[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4794: 100%|█| 1/1 [01:36<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:32:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4794[0m, global step [1;36m4795[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4799: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:37:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4799[0m, global step [1;36m4800[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4804: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:39:44][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4804[0m, global step [1;36m4805[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4809: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:42:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4809[0m, global step [1;36m4810[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4814: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:45:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4814[0m, global step [1;36m4815[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4819: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:47:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4819[0m, global step [1;36m4820[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4824: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:50:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4824[0m, global step [1;36m4825[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4829: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:53:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4829[0m, global step [1;36m4830[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4834: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:56:02][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4834[0m, global step [1;36m4835[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4839: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[04:58:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4839[0m, global step [1;36m4840[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4844: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:01:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4844[0m, global step [1;36m4845[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4849: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:04:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4849[0m, global step [1;36m4850[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4854: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:06:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4854[0m, global step [1;36m4855[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4859: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:09:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4859[0m, global step [1;36m4860[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4864: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:12:16][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4864[0m, global step [1;36m4865[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4869: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:14:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4869[0m, global step [1;36m4870[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4874: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:17:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4874[0m, global step [1;36m4875[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4879: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:20:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4879[0m, global step [1;36m4880[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4884: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:23:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4884[0m, global step [1;36m4885[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4889: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:25:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4889[0m, global step [1;36m4890[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4894: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:28:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4894[0m, global step [1;36m4895[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4899: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:31:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4899[0m, global step [1;36m4900[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4904: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:33:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4904[0m, global step [1;36m4905[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4909: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:36:39][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4909[0m, global step [1;36m4910[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4914: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:39:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4914[0m, global step [1;36m4915[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4919: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:42:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4919[0m, global step [1;36m4920[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4924: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:44:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4924[0m, global step [1;36m4925[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4929: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:47:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4929[0m, global step [1;36m4930[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4934: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:50:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4934[0m, global step [1;36m4935[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4939: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:53:00][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4939[0m, global step [1;36m4940[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4944: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:55:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4944[0m, global step [1;36m4945[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4949: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[05:58:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4949[0m, global step [1;36m4950[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4954: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:01:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4954[0m, global step [1;36m4955[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4959: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:03:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4959[0m, global step [1;36m4960[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4964: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:06:39][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4964[0m, global step [1;36m4965[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4969: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:09:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4969[0m, global step [1;36m4970[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4974: 100%|█| 1/1 [02:46<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:18:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4974[0m, global step [1;36m4975[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4979: 100%|█| 1/1 [02:11<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:28:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4979[0m, global step [1;36m4980[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4984: 100%|█| 1/1 [01:30<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:37:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4984[0m, global step [1;36m4985[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4989: 100%|█| 1/1 [02:16<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:46:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4989[0m, global step [1;36m4990[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4994: 100%|█| 1/1 [02:29<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[06:57:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4994[0m, global step [1;36m4995[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 4999: 100%|█| 1/1 [01:44<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:07:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m4999[0m, global step [1;36m5000[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5004: 100%|█| 1/1 [01:36<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:15:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5004[0m, global step [1;36m5005[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m5004[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 5009: 100%|█| 1/1 [02:40<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:25:30][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5009[0m, global step [1;36m5010[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5014: 100%|█| 1/1 [01:50<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:36:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5014[0m, global step [1;36m5015[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5019: 100%|█| 1/1 [01:43<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:45:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5019[0m, global step [1;36m5020[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m5019[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 5024: 100%|█| 1/1 [01:59<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[07:54:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5024[0m, global step [1;36m5025[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5029: 100%|█| 1/1 [01:30<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:05:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5029[0m, global step [1;36m5030[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5034: 100%|█| 1/1 [01:47<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:13:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5034[0m, global step [1;36m5035[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5039: 100%|█| 1/1 [00:57<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:20:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5039[0m, global step [1;36m5040[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5044: 100%|█| 1/1 [02:39<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:31:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5044[0m, global step [1;36m5045[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5049: 100%|█| 1/1 [01:36<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:38:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5049[0m, global step [1;36m5050[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5054: 100%|█| 1/1 [01:24<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:45:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5054[0m, global step [1;36m5055[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m5054[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 5059: 100%|█| 1/1 [00:43<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:48:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5059[0m, global step [1;36m5060[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5064: 100%|█| 1/1 [01:37<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[08:55:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5064[0m, global step [1;36m5065[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5069: 100%|█| 1/1 [01:31<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:03:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5069[0m, global step [1;36m5070[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5074: 100%|█| 1/1 [00:54<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:10:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5074[0m, global step [1;36m5075[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5079: 100%|█| 1/1 [00:57<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:14:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5079[0m, global step [1;36m5080[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5084: 100%|█| 1/1 [01:11<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:20:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5084[0m, global step [1;36m5085[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5089: 100%|█| 1/1 [02:23<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:28:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5089[0m, global step [1;36m5090[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5094: 100%|█| 1/1 [00:59<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:36:07][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5094[0m, global step [1;36m5095[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5099: 100%|█| 1/1 [01:38<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:40:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5099[0m, global step [1;36m5100[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5104: 100%|█| 1/1 [00:48<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:46:16][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5104[0m, global step [1;36m5105[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5109: 100%|█| 1/1 [01:57<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[09:51:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5109[0m, global step [1;36m5110[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5114: 100%|█| 1/1 [01:49<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:00:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5114[0m, global step [1;36m5115[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5119: 100%|█| 1/1 [01:42<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:06:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5119[0m, global step [1;36m5120[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5124: 100%|█| 1/1 [00:52<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:12:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5124[0m, global step [1;36m5125[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5129: 100%|█| 1/1 [01:09<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:16:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5129[0m, global step [1;36m5130[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5134: 100%|█| 1/1 [01:30<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:24:38][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5134[0m, global step [1;36m5135[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5139: 100%|█| 1/1 [01:49<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:31:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5139[0m, global step [1;36m5140[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5144: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:37:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5144[0m, global step [1;36m5145[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5149: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:40:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5149[0m, global step [1;36m5150[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5154: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:43:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5154[0m, global step [1;36m5155[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5159: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:46:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5159[0m, global step [1;36m5160[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5164: 100%|█| 1/1 [01:13<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:50:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5164[0m, global step [1;36m5165[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5169: 100%|█| 1/1 [01:17<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:56:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5169[0m, global step [1;36m5170[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5174: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[10:59:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5174[0m, global step [1;36m5175[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5179: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:02:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5179[0m, global step [1;36m5180[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5184: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:05:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5184[0m, global step [1;36m5185[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5189: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:08:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5189[0m, global step [1;36m5190[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5194: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:11:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5194[0m, global step [1;36m5195[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5199: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:13:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5199[0m, global step [1;36m5200[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5204: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:16:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5204[0m, global step [1;36m5205[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5209: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:19:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5209[0m, global step [1;36m5210[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5214: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:22:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5214[0m, global step [1;36m5215[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5219: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:24:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5219[0m, global step [1;36m5220[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5224: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:27:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5224[0m, global step [1;36m5225[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5229: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:30:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5229[0m, global step [1;36m5230[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5234: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:32:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5234[0m, global step [1;36m5235[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5239: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:35:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5239[0m, global step [1;36m5240[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5244: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:38:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5244[0m, global step [1;36m5245[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5249: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:41:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5249[0m, global step [1;36m5250[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5254: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:43:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5254[0m, global step [1;36m5255[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5259: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:46:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5259[0m, global step [1;36m5260[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5264: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:49:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5264[0m, global step [1;36m5265[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5269: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:52:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5269[0m, global step [1;36m5270[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5274: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:54:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5274[0m, global step [1;36m5275[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5279: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[11:57:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5279[0m, global step [1;36m5280[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5284: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:00:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5284[0m, global step [1;36m5285[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5289: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:02:57][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5289[0m, global step [1;36m5290[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5294: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:05:39][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5294[0m, global step [1;36m5295[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5299: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:08:30][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5299[0m, global step [1;36m5300[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5304: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:11:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5304[0m, global step [1;36m5305[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5309: 100%|█| 1/1 [01:05<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:15:50][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5309[0m, global step [1;36m5310[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5314: 100%|█| 1/1 [01:52<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:25:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5314[0m, global step [1;36m5315[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5319: 100%|█| 1/1 [01:39<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:35:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5319[0m, global step [1;36m5320[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5324: 100%|█| 1/1 [01:39<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:42:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5324[0m, global step [1;36m5325[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5329: 100%|█| 1/1 [02:02<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[12:52:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5329[0m, global step [1;36m5330[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5334: 100%|█| 1/1 [01:43<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:01:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5334[0m, global step [1;36m5335[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5339: 100%|█| 1/1 [01:38<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:09:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5339[0m, global step [1;36m5340[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5344: 100%|█| 1/1 [02:17<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:19:39][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5344[0m, global step [1;36m5345[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5349: 100%|█| 1/1 [02:07<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:28:34][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5349[0m, global step [1;36m5350[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5354: 100%|█| 1/1 [02:06<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.184,[2;36m[13:34:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5354[0m, global step [1;36m5355[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5359: 100%|█| 1/1 [02:10<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:43:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5359[0m, global step [1;36m5360[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5364: 100%|█| 1/1 [01:03<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:51:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5364[0m, global step [1;36m5365[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5369: 100%|█| 1/1 [00:49<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[13:56:44][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5369[0m, global step [1;36m5370[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5374: 100%|█| 1/1 [00:49<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:01:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5374[0m, global step [1;36m5375[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5379: 100%|█| 1/1 [01:53<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:09:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5379[0m, global step [1;36m5380[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5384: 100%|█| 1/1 [01:39<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:16:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5384[0m, global step [1;36m5385[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5389: 100%|█| 1/1 [01:19<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:21:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5389[0m, global step [1;36m5390[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5394: 100%|█| 1/1 [00:46<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:25:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5394[0m, global step [1;36m5395[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5399: 100%|█| 1/1 [01:33<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:32:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5399[0m, global step [1;36m5400[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5404: 100%|█| 1/1 [01:02<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:39:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5404[0m, global step [1;36m5405[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m5404[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 5409: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:44:16][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5409[0m, global step [1;36m5410[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5414: 100%|█| 1/1 [02:07<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:49:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5414[0m, global step [1;36m5415[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5419: 100%|█| 1/1 [02:11<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[14:57:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5419[0m, global step [1;36m5420[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5424: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:02:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5424[0m, global step [1;36m5425[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5429: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:05:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5429[0m, global step [1;36m5430[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5434: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:08:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5434[0m, global step [1;36m5435[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5439: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:11:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5439[0m, global step [1;36m5440[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5444: 100%|█| 1/1 [01:12<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:14:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5444[0m, global step [1;36m5445[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5449: 100%|█| 1/1 [01:37<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:21:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5449[0m, global step [1;36m5450[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5454: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:25:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5454[0m, global step [1;36m5455[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5459: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:27:48][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5459[0m, global step [1;36m5460[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5464: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:30:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5464[0m, global step [1;36m5465[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5469: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:33:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5469[0m, global step [1;36m5470[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5474: 100%|█| 1/1 [01:13<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:39:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5474[0m, global step [1;36m5475[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5479: 100%|█| 1/1 [00:54<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:44:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5479[0m, global step [1;36m5480[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5484: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:47:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5484[0m, global step [1;36m5485[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5489: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:50:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5489[0m, global step [1;36m5490[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5494: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:52:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5494[0m, global step [1;36m5495[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5499: 100%|█| 1/1 [01:07<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[15:56:33][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5499[0m, global step [1;36m5500[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5504: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:01:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5504[0m, global step [1;36m5505[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5509: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:03:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5509[0m, global step [1;36m5510[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5514: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:06:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5514[0m, global step [1;36m5515[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5519: 100%|█| 1/1 [00:33<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:08:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5519[0m, global step [1;36m5520[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5524: 100%|█| 1/1 [00:54<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:11:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5524[0m, global step [1;36m5525[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5529: 100%|█| 1/1 [00:58<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:15:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5529[0m, global step [1;36m5530[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5534: 100%|█| 1/1 [00:45<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:19:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5534[0m, global step [1;36m5535[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5539: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:22:59][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5539[0m, global step [1;36m5540[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5544: 100%|█| 1/1 [00:58<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:26:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5544[0m, global step [1;36m5545[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5549: 100%|█| 1/1 [01:01<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.184, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:30:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5549[0m, global step [1;36m5550[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5554: 100%|█| 1/1 [00:49<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:34:23][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5554[0m, global step [1;36m5555[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5559: 100%|█| 1/1 [01:13<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:38:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5559[0m, global step [1;36m5560[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5564: 100%|█| 1/1 [00:58<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:42:13][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5564[0m, global step [1;36m5565[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5569: 100%|█| 1/1 [00:47<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:46:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5569[0m, global step [1;36m5570[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5574: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:49:54][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5574[0m, global step [1;36m5575[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5579: 100%|█| 1/1 [01:00<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:54:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5579[0m, global step [1;36m5580[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5584: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[16:57:30][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5584[0m, global step [1;36m5585[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5589: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:01:49][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5589[0m, global step [1;36m5590[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5594: 100%|█| 1/1 [01:01<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:05:38][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5594[0m, global step [1;36m5595[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5599: 100%|█| 1/1 [00:56<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:09:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5599[0m, global step [1;36m5600[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5604: 100%|█| 1/1 [00:49<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:13:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5604[0m, global step [1;36m5605[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5609: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:17:20][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5609[0m, global step [1;36m5610[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5614: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:20:39][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5614[0m, global step [1;36m5615[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5619: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:23:29][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5619[0m, global step [1;36m5620[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5624: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:26:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5624[0m, global step [1;36m5625[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5629: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:29:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5629[0m, global step [1;36m5630[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5634: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:32:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5634[0m, global step [1;36m5635[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5639: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:35:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5639[0m, global step [1;36m5640[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5644: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:37:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5644[0m, global step [1;36m5645[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5649: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:40:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5649[0m, global step [1;36m5650[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5654: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:43:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5654[0m, global step [1;36m5655[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5659: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:46:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5659[0m, global step [1;36m5660[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5664: 100%|█| 1/1 [00:46<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:49:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5664[0m, global step [1;36m5665[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5669: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:52:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5669[0m, global step [1;36m5670[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5674: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:55:18][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5674[0m, global step [1;36m5675[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5679: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[17:58:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5679[0m, global step [1;36m5680[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5684: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:01:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5684[0m, global step [1;36m5685[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5689: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:04:03][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5689[0m, global step [1;36m5690[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5694: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:07:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5694[0m, global step [1;36m5695[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5699: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:09:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5699[0m, global step [1;36m5700[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5704: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:12:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5704[0m, global step [1;36m5705[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m5704[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 5709: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:15:46][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5709[0m, global step [1;36m5710[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5714: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:18:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5714[0m, global step [1;36m5715[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5719: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:21:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5719[0m, global step [1;36m5720[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5724: 100%|█| 1/1 [00:34<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:24:27][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5724[0m, global step [1;36m5725[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5729: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:27:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5729[0m, global step [1;36m5730[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5734: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:30:21][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5734[0m, global step [1;36m5735[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5739: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:33:13][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5739[0m, global step [1;36m5740[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5744: 100%|█| 1/1 [00:47<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:36:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5744[0m, global step [1;36m5745[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5749: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:40:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5749[0m, global step [1;36m5750[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5754: 100%|█| 1/1 [01:13<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:44:15][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5754[0m, global step [1;36m5755[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5759: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:48:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5759[0m, global step [1;36m5760[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5764: 100%|█| 1/1 [01:33<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:52:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5764[0m, global step [1;36m5765[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5769: 100%|█| 1/1 [00:54<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[18:56:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5769[0m, global step [1;36m5770[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5774: 100%|█| 1/1 [01:13<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:00:37][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5774[0m, global step [1;36m5775[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5779: 100%|█| 1/1 [00:43<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:04:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5779[0m, global step [1;36m5780[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5784: 100%|█| 1/1 [01:16<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:09:07][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5784[0m, global step [1;36m5785[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5789: 100%|█| 1/1 [00:48<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:13:36][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5789[0m, global step [1;36m5790[0m: [32m'val_loss'[0m reached [1;36m1.82831[0m [1m([0mbest [1;36m1.82831[0m[1m)[0m, saving model to                                  [2mmodel_checkpoint.py:753[0m
[2;36m           [0m         [32m'/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/checkpoints/G-Align/Aug13-22:00-46d6f90d/checkpoints/gfm-[0m[32mepoc[0m [2m                       [0m
[2;36m           [0m         [32mh[0m[32m=[0m[32m5789[0m[32m-[0m[32mval_loss[0m[32m=[0m[32m1[0m[32m.8283.ckpt'[0m as top [1;36m3[0m                                                                                     [2m                       [0m
Epoch 5794: 100%|█| 1/1 [01:00<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:17:53][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5794[0m, global step [1;36m5795[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5799: 100%|█| 1/1 [00:45<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:22:26][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5799[0m, global step [1;36m5800[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5804: 100%|█| 1/1 [00:40<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:26:42][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5804[0m, global step [1;36m5805[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5809: 100%|█| 1/1 [00:55<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:31:39][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5809[0m, global step [1;36m5810[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5814: 100%|█| 1/1 [01:04<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:35:56][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5814[0m, global step [1;36m5815[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5819: 100%|█| 1/1 [01:08<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:41:01][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5819[0m, global step [1;36m5820[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5824: 100%|█| 1/1 [01:04<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:45:14][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5824[0m, global step [1;36m5825[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5829: 100%|█| 1/1 [00:48<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:50:12][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5829[0m, global step [1;36m5830[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5834: 100%|█| 1/1 [00:48<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:54:41][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5834[0m, global step [1;36m5835[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5839: 100%|█| 1/1 [01:13<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[19:59:25][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5839[0m, global step [1;36m5840[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5844: 100%|█| 1/1 [00:44<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:03:45][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5844[0m, global step [1;36m5845[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5849: 100%|█| 1/1 [01:13<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:07:31][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5849[0m, global step [1;36m5850[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5854: 100%|█| 1/1 [00:45<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:10:47][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5854[0m, global step [1;36m5855[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5859: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:14:13][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5859[0m, global step [1;36m5860[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5864: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:17:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5864[0m, global step [1;36m5865[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5869: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:20:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5869[0m, global step [1;36m5870[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5874: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:23:05][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5874[0m, global step [1;36m5875[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5879: 100%|█| 1/1 [00:43<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:26:07][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5879[0m, global step [1;36m5880[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5884: 100%|█| 1/1 [00:43<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:29:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5884[0m, global step [1;36m5885[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5889: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:32:06][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5889[0m, global step [1;36m5890[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5894: 100%|█| 1/1 [00:43<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:35:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5894[0m, global step [1;36m5895[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5899: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:38:09][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5899[0m, global step [1;36m5900[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5904: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:41:11][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5904[0m, global step [1;36m5905[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5909: 100%|█| 1/1 [00:35<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:44:10][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5909[0m, global step [1;36m5910[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5914: 100%|█| 1/1 [00:43<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:47:13][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5914[0m, global step [1;36m5915[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5919: 100%|█| 1/1 [00:36<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:50:19][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5919[0m, global step [1;36m5920[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5924: 100%|█| 1/1 [00:41<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:53:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5924[0m, global step [1;36m5925[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5929: 100%|█| 1/1 [00:39<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:56:24][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5929[0m, global step [1;36m5930[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5934: 100%|█| 1/1 [00:42<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[20:59:39][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5934[0m, global step [1;36m5935[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5939: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:02:35][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5939[0m, global step [1;36m5940[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5944: 100%|█| 1/1 [00:47<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:05:51][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5944[0m, global step [1;36m5945[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5949: 100%|█| 1/1 [00:43<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:08:58][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5949[0m, global step [1;36m5950[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5954: 100%|█| 1/1 [00:38<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:11:43][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5954[0m, global step [1;36m5955[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5959: 100%|█| 1/1 [00:37<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:14:38][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5959[0m, global step [1;36m5960[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5964: 100%|█| 1/1 [00:32<00:00,  0.03it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:17:32][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5964[0m, global step [1;36m5965[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5969: 100%|█| 1/1 [01:05<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:20:55][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5969[0m, global step [1;36m5970[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5974: 100%|█| 1/1 [01:00<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:25:13][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5974[0m, global step [1;36m5975[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5979: 100%|█| 1/1 [00:54<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:30:17][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5979[0m, global step [1;36m5980[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5984: 100%|█| 1/1 [00:53<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:35:22][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5984[0m, global step [1;36m5985[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5989: 100%|█| 1/1 [01:14<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:39:52][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5989[0m, global step [1;36m5990[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5994: 100%|█| 1/1 [00:55<00:00,  0.02it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:45:04][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5994[0m, global step [1;36m5995[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5999: 100%|█| 1/1 [01:22<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m[21:50:08][0m[2;36m [0m[34mINFO    [0m Epoch [1;36m5999[0m, global step [1;36m6000[0m: [32m'val_loss'[0m was not in top [1;36m3[0m                                                                 [2mmodel_checkpoint.py:709[0m
Epoch 5999: 100%|█| 1/1 [01:22<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,[2;36m          [0m[2;36m [0m[34mINFO    [0m `Trainer.fit` stopped: `[33mmax_epochs[0m=[1;36m6000[0m` reached.                                                                                 [2mfit_loop.py:191[0m
Epoch 5999: 100%|█| 1/1 [01:22<00:00,  0.01it/s, v_num=qlut, train_loss_step=1.830, train_acc_step=0.183, train_loss_epoch=1.830, train_acc_epoch=0.183,
[2;36m[21:50:10][0m[2;36m [0m[34mINFO    [0m Final model saved to:                                                                                                             [2mpretrain.py:277[0m
[2;36m           [0m         [35m/home/zhuowei/MyProj/G-Align-v2/G-Align-v2/generated_files/output/G-Align/[0m[95mAug13-22[0m:[1;36m00[0m-46d6f90d/final_gfm_model.pt                 [2m               [0m
[2;36m          [0m[2;36m [0m[34mINFO    [0m Running final validation[33m...[0m                                                                                                       [2mpretrain.py:278[0m
[2;36m          [0m[2;36m [0m[34mINFO    [0m LOCAL_RANK: [1;36m0[0m - CUDA_VISIBLE_DEVICES: [1m[[0m[1;36m0[0m,[1;36m1[0m,[1;36m2[0m,[1;36m3[0m[1m][0m                                                                                        [2mcuda.py:61[0m
Testing DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  0.23it/s]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m [0m[1m       Test metric       [0m[1m [0m┃[1m [0m[1m      DataLoader 0       [0m[1m [0m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m [0m[36m         val_acc         [0m[36m [0m│[35m [0m[35m   0.18333332240581512   [0m[35m [0m│
│[36m [0m[36m        val_loss         [0m[36m [0m│[35m [0m[35m   1.8283061981201172    [0m[35m [0m│
└───────────────────────────┴───────────────────────────┘
[2;36m[21:50:22][0m[2;36m [0m[34mINFO    [0m Pretraining completed successfully!                                                                                               [2mpretrain.py:281[0m
[2;36m          [0m[2;36m [0m[34mINFO    [0m Final test results: [1m[[0m[1m{[0m[32m'val_loss'[0m: [1;36m1.8283061981201172[0m, [32m'val_acc'[0m: [1;36m0.18333332240581512[0m[1m}[0m[1m][0m                                            [2mpretrain.py:282[0m
